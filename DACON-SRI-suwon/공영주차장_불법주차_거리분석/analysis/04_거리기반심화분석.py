#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°€ì„¤ 1: ê³µì˜ì£¼ì°¨ì¥ ì ‘ê·¼ì„± ê¸°ë°˜ ë§ì¶¤í˜• ì •ì±…
ê±°ë¦¬ ê¸°ë°˜ ì‹¬í™” ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Pretendard í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Pretendard'
plt.rcParams['axes.unicode_minus'] = False

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ê±°ë¦¬ ê¸°ë°˜ ì‹¬í™” ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ë¡œë“œ
    distance_df = pd.read_csv('data/ê±°ë¦¬ë§¤íŠ¸ë¦­ìŠ¤.csv', encoding='utf-8-sig')
    
    # ì£¼ì°¨ë‹¨ì† ë°ì´í„° ë¡œë“œ
    violations_df = pd.read_csv('data/ì •ë¦¬ëœ_ì£¼ì°¨ë‹¨ì†ë°ì´í„°.csv', encoding='utf-8-sig')
    
    # ê³µì˜ì£¼ì°¨ì¥ ìœ„ê²½ë„ ë°ì´í„° ë¡œë“œ
    parking_coords = pd.read_csv('data/ê³µì˜ì£¼ì°¨ì¥_ìœ„ê²½ë„.csv', encoding='utf-8-sig')
    
    print(f"ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤: {len(distance_df):,}ê±´")
    print(f"ì£¼ì°¨ë‹¨ì† ë°ì´í„°: {len(violations_df):,}ê±´")
    print(f"ê³µì˜ì£¼ì°¨ì¥ ìœ„ê²½ë„: {len(parking_coords):,}ê±´")
    
    return distance_df, violations_df, parking_coords

def analyze_distance_patterns(distance_df):
    """ê±°ë¦¬ íŒ¨í„´ ì‹¬í™” ë¶„ì„"""
    print("\n=== ğŸ“Š ê±°ë¦¬ íŒ¨í„´ ì‹¬í™” ë¶„ì„ ===")
    
    # 1. ê±°ë¦¬ í†µê³„
    distance_stats = distance_df['ê±°ë¦¬_km'].describe()
    print("\n1ï¸âƒ£ ê±°ë¦¬ í†µê³„:")
    print(f"   í‰ê·  ê±°ë¦¬: {distance_stats['mean']:.2f}km")
    print(f"   ì¤‘ê°„ê°’ ê±°ë¦¬: {distance_stats['50%']:.2f}km")
    print(f"   í‘œì¤€í¸ì°¨: {distance_stats['std']:.2f}km")
    print(f"   ìµœëŒ€ ê±°ë¦¬: {distance_stats['max']:.2f}km")
    print(f"   ìµœì†Œ ê±°ë¦¬: {distance_stats['min']:.2f}km")
    
    # 2. ê±°ë¦¬ êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„
    print("\n2ï¸âƒ£ ê±°ë¦¬ êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„:")
    distance_df['ê±°ë¦¬êµ¬ê°„'] = pd.cut(distance_df['ê±°ë¦¬_km'], 
                                  bins=[0, 0.5, 1, 2, 3, 5, 10], 
                                  labels=['0.5kmì´ë‚´', '0.5-1km', '1-2km', '2-3km', '3-5km', '5kmì´ìƒ'])
    
    distance_analysis = distance_df.groupby('ê±°ë¦¬êµ¬ê°„').agg({
        'ê±°ë¦¬_km': ['count', 'mean', 'std'],
        'ë‹¨ì†ì¥ì†Œ': 'nunique'
    }).round(2)
    
    print(distance_analysis)
    
    # 3. ê³µì˜ì£¼ì°¨ì¥ë³„ ì ‘ê·¼ì„± ë¶„ì„
    print("\n3ï¸âƒ£ ê³µì˜ì£¼ì°¨ì¥ë³„ ì ‘ê·¼ì„± ë¶„ì„:")
    parking_analysis = distance_df.groupby('ê³µì˜ì£¼ì°¨ì¥').agg({
        'ê±°ë¦¬_km': ['count', 'mean', 'min', 'max'],
        'ë‹¨ì†ì¥ì†Œ': 'nunique'
    }).round(2)
    
    # ìƒìœ„ 10ê°œ ê³µì˜ì£¼ì°¨ì¥ (ë‹¨ì† ê±´ìˆ˜ ê¸°ì¤€)
    top_parking = parking_analysis[('ê±°ë¦¬_km', 'count')].sort_values(ascending=False).head(10)
    print("ìƒìœ„ 10ê°œ ê³µì˜ì£¼ì°¨ì¥ (ë‹¨ì† ê±´ìˆ˜):")
    for parking, count in top_parking.items():
        mean_dist = parking_analysis.loc[parking, ('ê±°ë¦¬_km', 'mean')]
        unique_locations = parking_analysis.loc[parking, ('ë‹¨ì†ì¥ì†Œ', 'nunique')]
        print(f"   {parking}: {count:,}ê±´ (í‰ê· ê±°ë¦¬: {mean_dist:.2f}km, ë‹¨ì†ì¥ì†Œ: {unique_locations}ê°œ)")
    
    return distance_analysis, parking_analysis

def analyze_hotspots_by_distance(distance_df, violations_df):
    """ê±°ë¦¬ë³„ í•«ìŠ¤íŒŸ ë¶„ì„"""
    print("\n=== ğŸ”¥ ê±°ë¦¬ë³„ í•«ìŠ¤íŒŸ ë¶„ì„ ===")
    
    # ë‹¨ì†ì¥ì†Œë³„ ë‹¨ì† ê±´ìˆ˜ ê³„ì‚°
    violation_counts = violations_df['ë‹¨ì†ì¥ì†Œ'].value_counts().reset_index()
    violation_counts.columns = ['ë‹¨ì†ì¥ì†Œ', 'ë‹¨ì†ê±´ìˆ˜']
    
    # ê±°ë¦¬ ë°ì´í„°ì™€ ë³‘í•©
    distance_violations = distance_df.merge(violation_counts, on='ë‹¨ì†ì¥ì†Œ', how='left')
    
    # ê±°ë¦¬ êµ¬ê°„ë³„ í•«ìŠ¤íŒŸ ë¶„ì„
    print("\n1ï¸âƒ£ ê±°ë¦¬ êµ¬ê°„ë³„ í•«ìŠ¤íŒŸ:")
    distance_df['ê±°ë¦¬êµ¬ê°„'] = pd.cut(distance_df['ê±°ë¦¬_km'], 
                                  bins=[0, 0.5, 1, 2, 3, 5, 10], 
                                  labels=['0.5kmì´ë‚´', '0.5-1km', '1-2km', '2-3km', '3-5km', '5kmì´ìƒ'])
    
    hotspot_analysis = distance_violations.groupby('ê±°ë¦¬êµ¬ê°„').agg({
        'ë‹¨ì†ê±´ìˆ˜': ['mean', 'max', 'sum'],
        'ë‹¨ì†ì¥ì†Œ': 'nunique'
    }).round(2)
    
    print(hotspot_analysis)
    
    # 2. ê±°ë¦¬ë³„ ë‹¨ì† ë¹ˆë„ ìƒê´€ê´€ê³„
    print("\n2ï¸âƒ£ ê±°ë¦¬ì™€ ë‹¨ì† ë¹ˆë„ì˜ ìƒê´€ê´€ê³„:")
    correlation = distance_violations['ê±°ë¦¬_km'].corr(distance_violations['ë‹¨ì†ê±´ìˆ˜'])
    print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.3f}")
    
    if correlation > 0.1:
        print("   â†’ ê±°ë¦¬ê°€ ë©€ìˆ˜ë¡ ë‹¨ì† ë¹ˆë„ê°€ ë†’ìŒ (ê³µì˜ì£¼ì°¨ì¥ ì ‘ê·¼ì„± ë¬¸ì œ)")
    elif correlation < -0.1:
        print("   â†’ ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë‹¨ì† ë¹ˆë„ê°€ ë†’ìŒ (í•«ìŠ¤íŒŸ ì§€ì—­)")
    else:
        print("   â†’ ê±°ë¦¬ì™€ ë‹¨ì† ë¹ˆë„ ê°„ ìƒê´€ê´€ê³„ê°€ ì•½í•¨")
    
    return distance_violations, hotspot_analysis

def analyze_parking_deserts(distance_df, parking_coords):
    """ì£¼ì°¨ì¥ ì‚¬ê°ì§€ëŒ€ ë¶„ì„"""
    print("\n=== ğŸœï¸ ì£¼ì°¨ì¥ ì‚¬ê°ì§€ëŒ€ ë¶„ì„ ===")
    
    # 1. ì‚¬ê°ì§€ëŒ€ ì •ì˜ (2km ì´ìƒ)
    desert_threshold = 2.0
    parking_deserts = distance_df[distance_df['ê±°ë¦¬_km'] >= desert_threshold]
    
    print(f"\n1ï¸âƒ£ ì£¼ì°¨ì¥ ì‚¬ê°ì§€ëŒ€ í˜„í™© (2km ì´ìƒ):")
    print(f"   ì‚¬ê°ì§€ëŒ€ ë‹¨ì† ê±´ìˆ˜: {len(parking_deserts):,}ê±´")
    print(f"   ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨: {len(parking_deserts)/len(distance_df)*100:.1f}%")
    
    # 2. ì‚¬ê°ì§€ëŒ€ ê±°ë¦¬ ë¶„í¬
    desert_stats = parking_deserts['ê±°ë¦¬_km'].describe()
    print(f"\n2ï¸âƒ£ ì‚¬ê°ì§€ëŒ€ ê±°ë¦¬ í†µê³„:")
    print(f"   í‰ê·  ê±°ë¦¬: {desert_stats['mean']:.2f}km")
    print(f"   ì¤‘ê°„ê°’ ê±°ë¦¬: {desert_stats['50%']:.2f}km")
    print(f"   ìµœëŒ€ ê±°ë¦¬: {desert_stats['max']:.2f}km")
    
    # 3. ì‚¬ê°ì§€ëŒ€ ì§€ì—­ë³„ ë¶„í¬
    print(f"\n3ï¸âƒ£ ì‚¬ê°ì§€ëŒ€ ì§€ì—­ë³„ ë¶„í¬:")
    desert_locations = parking_deserts['ë‹¨ì†ì¥ì†Œ'].nunique()
    total_locations = distance_df['ë‹¨ì†ì¥ì†Œ'].nunique()
    print(f"   ì‚¬ê°ì§€ëŒ€ ë‹¨ì†ì¥ì†Œ: {desert_locations:,}ê°œ")
    print(f"   ì „ì²´ ë‹¨ì†ì¥ì†Œ: {total_locations:,}ê°œ")
    print(f"   ì‚¬ê°ì§€ëŒ€ ë¹„ìœ¨: {desert_locations/total_locations*100:.1f}%")
    
    return parking_deserts

def create_distance_based_policy(distance_df, violations_df):
    """ê±°ë¦¬ ê¸°ë°˜ ì •ì±… ì œì•ˆ"""
    print("\n=== ğŸ¯ ê±°ë¦¬ ê¸°ë°˜ ì •ì±… ì œì•ˆ ===")
    
    # ê±°ë¦¬ êµ¬ê°„ë³„ ì •ì±… ë§¤íŠ¸ë¦­ìŠ¤
    distance_policy = {
        '0.5kmì´ë‚´': {
            'ìœ ì˜ˆì‹œê°„': '30ë¶„',
            'ì •ì±…ê·¼ê±°': 'ê³µì˜ì£¼ì°¨ì¥ ê·¼ì ‘, ëŒ€ì•ˆ ì£¼ì°¨ ê°€ëŠ¥',
            'ì˜ˆìƒíš¨ê³¼': 'ìµœì†Œí•œì˜ ì£¼ì°¨ í¸ì˜ì„± ì œê³µ',
            'ì ìš©ëŒ€ìƒ': 'ê³µì˜ì£¼ì°¨ì¥ ì¸ê·¼ ì§€ì—­'
        },
        '0.5-1km': {
            'ìœ ì˜ˆì‹œê°„': '45ë¶„',
            'ì •ì±…ê·¼ê±°': 'ë³´í–‰ ê°€ëŠ¥ ê±°ë¦¬, ì œí•œì  ì£¼ì°¨ í—ˆìš©',
            'ì˜ˆìƒíš¨ê³¼': 'ë³´í–‰ ê±°ë¦¬ ë‚´ ì£¼ì°¨ í¸ì˜ì„±',
            'ì ìš©ëŒ€ìƒ': 'ë³´í–‰ ê°€ëŠ¥ ì§€ì—­'
        },
        '1-2km': {
            'ìœ ì˜ˆì‹œê°„': '1ì‹œê°„',
            'ì •ì±…ê·¼ê±°': 'ë³´í–‰ ê°€ëŠ¥í•˜ë‚˜ ë¶ˆí¸, ì ë‹¹í•œ ìœ ì˜ˆ',
            'ì˜ˆìƒíš¨ê³¼': 'ì ë‹¹í•œ ì£¼ì°¨ í¸ì˜ì„± ì œê³µ',
            'ì ìš©ëŒ€ìƒ': 'ë³´í–‰ ê°€ëŠ¥ ì§€ì—­'
        },
        '2-3km': {
            'ìœ ì˜ˆì‹œê°„': '1.5ì‹œê°„',
            'ì •ì±…ê·¼ê±°': 'ë³´í–‰ ì–´ë ¤ì›€, ì¶©ë¶„í•œ ìœ ì˜ˆ í•„ìš”',
            'ì˜ˆìƒíš¨ê³¼': 'ì¶©ë¶„í•œ ì£¼ì°¨ í¸ì˜ì„± ì œê³µ',
            'ì ìš©ëŒ€ìƒ': 'ë³´í–‰ ì–´ë ¤ìš´ ì§€ì—­'
        },
        '3-5km': {
            'ìœ ì˜ˆì‹œê°„': '2ì‹œê°„',
            'ì •ì±…ê·¼ê±°': 'ë³´í–‰ ë§¤ìš° ì–´ë ¤ì›€, í™•ëŒ€ ìœ ì˜ˆ í•„ìš”',
            'ì˜ˆìƒíš¨ê³¼': 'ëŒ€í­ì ì¸ ì£¼ì°¨ í¸ì˜ì„± ì œê³µ',
            'ì ìš©ëŒ€ìƒ': 'ë³´í–‰ ë§¤ìš° ì–´ë ¤ìš´ ì§€ì—­'
        },
        '5kmì´ìƒ': {
            'ìœ ì˜ˆì‹œê°„': '2.5ì‹œê°„',
            'ì •ì±…ê·¼ê±°': 'ê³µì˜ì£¼ì°¨ì¥ ì ‘ê·¼ ì–´ë ¤ì›€, ìµœëŒ€ ìœ ì˜ˆ',
            'ì˜ˆìƒíš¨ê³¼': 'ìµœëŒ€í•œì˜ ì£¼ì°¨ í¸ì˜ì„± ì œê³µ',
            'ì ìš©ëŒ€ìƒ': 'ì‚¬ê°ì§€ëŒ€ ì§€ì—­'
        }
    }
    
    # ê±°ë¦¬ êµ¬ê°„ë³„ í†µê³„
    distance_df['ê±°ë¦¬êµ¬ê°„'] = pd.cut(distance_df['ê±°ë¦¬_km'], 
                                  bins=[0, 0.5, 1, 2, 3, 5, 10], 
                                  labels=['0.5kmì´ë‚´', '0.5-1km', '1-2km', '2-3km', '3-5km', '5kmì´ìƒ'])
    
    distance_stats = distance_df.groupby('ê±°ë¦¬êµ¬ê°„').agg({
        'ê±°ë¦¬_km': ['count', 'mean'],
        'ë‹¨ì†ì¥ì†Œ': 'nunique'
    }).round(2)
    
    print("\n1ï¸âƒ£ ê±°ë¦¬ë³„ ë§ì¶¤í˜• ì •ì±… ë§¤íŠ¸ë¦­ìŠ¤:")
    print("=" * 100)
    print(f"{'ê±°ë¦¬êµ¬ê°„':<12} {'ë‹¨ì†ê±´ìˆ˜':<10} {'í‰ê· ê±°ë¦¬':<10} {'ë‹¨ì†ì¥ì†Œ':<10} {'ìœ ì˜ˆì‹œê°„':<10} {'ì •ì±…ê·¼ê±°':<30}")
    print("=" * 100)
    
    for distance_range in distance_stats.index:
        count = distance_stats.loc[distance_range, ('ê±°ë¦¬_km', 'count')]
        mean_dist = distance_stats.loc[distance_range, ('ê±°ë¦¬_km', 'mean')]
        locations = distance_stats.loc[distance_range, ('ë‹¨ì†ì¥ì†Œ', 'nunique')]
        policy = distance_policy[distance_range]
        
        print(f"{distance_range:<12} {count:<10,.0f} {mean_dist:<10.2f} {locations:<10.0f} {policy['ìœ ì˜ˆì‹œê°„']:<10} {policy['ì •ì±…ê·¼ê±°']:<30}")
    
    print("=" * 100)
    
    return distance_policy, distance_stats

def create_enhanced_visualizations(distance_df, distance_violations, parking_deserts):
    """í–¥ìƒëœ ì‹œê°í™” ìƒì„±"""
    print("\n=== ğŸ“ˆ í–¥ìƒëœ ì‹œê°í™” ìƒì„± ===")
    
    # 1. ê±°ë¦¬ë³„ ë‹¨ì† ë¹ˆë„ ì‚°ì ë„
    plt.figure(figsize=(15, 10))
    
    plt.subplot(2, 3, 1)
    plt.scatter(distance_violations['ê±°ë¦¬_km'], distance_violations['ë‹¨ì†ê±´ìˆ˜'], 
                alpha=0.6, color='#4A90E2', s=20)
    plt.title('ê±°ë¦¬ì™€ ë‹¨ì† ë¹ˆë„ì˜ ê´€ê³„', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ (km)', fontsize=12)
    plt.ylabel('ë‹¨ì† ê±´ìˆ˜', fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # 2. ê±°ë¦¬ êµ¬ê°„ë³„ ë‹¨ì† ê±´ìˆ˜ ë¶„í¬
    plt.subplot(2, 3, 2)
    distance_df['ê±°ë¦¬êµ¬ê°„'] = pd.cut(distance_df['ê±°ë¦¬_km'], 
                                  bins=[0, 0.5, 1, 2, 3, 5, 10], 
                                  labels=['0.5kmì´ë‚´', '0.5-1km', '1-2km', '2-3km', '3-5km', '5kmì´ìƒ'])
    distance_counts = distance_df.groupby('ê±°ë¦¬êµ¬ê°„').size()
    distance_counts.plot(kind='bar', color='#FF6B6B', edgecolor='darkred', linewidth=1.5)
    plt.title('ê±°ë¦¬ êµ¬ê°„ë³„ ë‹¨ì† ê±´ìˆ˜', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ êµ¬ê°„', fontsize=12)
    plt.ylabel('ë‹¨ì† ê±´ìˆ˜', fontsize=12)
    plt.xticks(rotation=45, fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    # 3. ê±°ë¦¬ë³„ í‰ê·  ë‹¨ì† ë¹ˆë„
    plt.subplot(2, 3, 3)
    distance_violations['ê±°ë¦¬êµ¬ê°„'] = pd.cut(distance_violations['ê±°ë¦¬_km'], 
                                         bins=[0, 0.5, 1, 2, 3, 5, 10], 
                                         labels=['0.5kmì´ë‚´', '0.5-1km', '1-2km', '2-3km', '3-5km', '5kmì´ìƒ'])
    avg_violations = distance_violations.groupby('ê±°ë¦¬êµ¬ê°„')['ë‹¨ì†ê±´ìˆ˜'].mean()
    avg_violations.plot(kind='bar', color='#4ECDC4', edgecolor='darkgreen', linewidth=1.5)
    plt.title('ê±°ë¦¬ êµ¬ê°„ë³„ í‰ê·  ë‹¨ì† ë¹ˆë„', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ êµ¬ê°„', fontsize=12)
    plt.ylabel('í‰ê·  ë‹¨ì† ê±´ìˆ˜', fontsize=12)
    plt.xticks(rotation=45, fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    # 4. ì‚¬ê°ì§€ëŒ€ ë¶„í¬
    plt.subplot(2, 3, 4)
    plt.hist(parking_deserts['ê±°ë¦¬_km'], bins=20, color='#FFEAA7', alpha=0.7, edgecolor='#DDA0DD', linewidth=1)
    plt.axvline(x=2.0, color='red', linestyle='--', label='ì‚¬ê°ì§€ëŒ€ ê¸°ì¤€ (2km)')
    plt.title('ì£¼ì°¨ì¥ ì‚¬ê°ì§€ëŒ€ ê±°ë¦¬ ë¶„í¬', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ (km)', fontsize=12)
    plt.ylabel('ë¹ˆë„', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 5. ê±°ë¦¬ë³„ ëˆ„ì  ë¶„í¬
    plt.subplot(2, 3, 5)
    sorted_distances = np.sort(distance_df['ê±°ë¦¬_km'])
    cumulative = np.arange(1, len(sorted_distances) + 1) / len(sorted_distances)
    plt.plot(sorted_distances, cumulative, color='#96CEB4', linewidth=2)
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50%')
    plt.axhline(y=0.8, color='orange', linestyle='--', alpha=0.7, label='80%')
    plt.title('ê±°ë¦¬ë³„ ëˆ„ì  ë¶„í¬', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ (km)', fontsize=12)
    plt.ylabel('ëˆ„ì  ë¹„ìœ¨', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 6. ê±°ë¦¬ êµ¬ê°„ë³„ ì •ì±… íš¨ê³¼ ì˜ˆì¸¡
    plt.subplot(2, 3, 6)
    distance_policy_effect = {
        '0.5kmì´ë‚´': 0.1,    # 10% ê°ì†Œ
        '0.5-1km': 0.15,     # 15% ê°ì†Œ
        '1-2km': 0.2,        # 20% ê°ì†Œ
        '2-3km': 0.25,       # 25% ê°ì†Œ
        '3-5km': 0.3,        # 30% ê°ì†Œ
        '5kmì´ìƒ': 0.35      # 35% ê°ì†Œ
    }
    
    effect_values = [distance_policy_effect.get(x, 0) for x in distance_counts.index]
    plt.bar(range(len(effect_values)), effect_values, color='#FF9999', edgecolor='darkred', linewidth=1.5)
    plt.title('ê±°ë¦¬ë³„ ì •ì±… íš¨ê³¼ ì˜ˆì¸¡', fontsize=14, fontweight='bold')
    plt.xlabel('ê±°ë¦¬ êµ¬ê°„', fontsize=12)
    plt.ylabel('ë‹¨ì† ê°ì†Œìœ¨ ì˜ˆì¸¡', fontsize=12)
    plt.xticks(range(len(effect_values)), distance_counts.index, rotation=45, fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('visualization/ê±°ë¦¬_ê¸°ë°˜_ì‹¬í™”ë¶„ì„.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()

def generate_comprehensive_report(distance_analysis, parking_analysis, hotspot_analysis, 
                                parking_deserts, distance_policy, distance_stats):
    """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\n=== ğŸ“‹ ê±°ë¦¬ ê¸°ë°˜ ì‹¬í™” ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ===")
    
    # 1. í•µì‹¬ í†µê³„ ìš”ì•½
    print("\n1ï¸âƒ£ í•µì‹¬ í†µê³„ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ë¶„ì„ ê±´ìˆ˜: {len(distance_analysis):,}ê±´")
    print(f"í‰ê·  ì ‘ê·¼ ê±°ë¦¬: {distance_analysis['ê±°ë¦¬_km']['mean'].mean():.2f}km")
    print(f"ì‚¬ê°ì§€ëŒ€ ë¹„ìœ¨: {len(parking_deserts)/len(distance_analysis)*100:.1f}%")
    print(f"ê³µì˜ì£¼ì°¨ì¥ ìˆ˜: {len(parking_analysis)}ê°œ")
    
    # 2. ê±°ë¦¬ë³„ ì •ì±… íš¨ê³¼ ì˜ˆì¸¡
    print("\n2ï¸âƒ£ ê±°ë¦¬ë³„ ì •ì±… íš¨ê³¼ ì˜ˆì¸¡")
    print("=" * 60)
    print(f"{'ê±°ë¦¬êµ¬ê°„':<12} {'ë‹¨ì†ê±´ìˆ˜':<10} {'ìœ ì˜ˆì‹œê°„':<10} {'ì˜ˆìƒê°ì†Œìœ¨':<12} {'ì ìš©ëŒ€ìƒ':<20}")
    print("-" * 60)
    
    for distance_range in distance_stats.index:
        count = distance_stats.loc[distance_range, ('ê±°ë¦¬_km', 'count')]
        policy = distance_policy[distance_range]
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ê°ì†Œìœ¨ ì˜ˆì¸¡
        if distance_range == '0.5kmì´ë‚´':
            reduction = 0.1
        elif distance_range == '0.5-1km':
            reduction = 0.15
        elif distance_range == '1-2km':
            reduction = 0.2
        elif distance_range == '2-3km':
            reduction = 0.25
        elif distance_range == '3-5km':
            reduction = 0.3
        else:  # 5kmì´ìƒ
            reduction = 0.35
        
        print(f"{distance_range:<12} {count:<10,.0f} {policy['ìœ ì˜ˆì‹œê°„']:<10} {reduction*100:<11.0f}% {policy['ì ìš©ëŒ€ìƒ']:<20}")
    
    # 3. ì •ì±… ìš°ì„ ìˆœìœ„
    print("\n3ï¸âƒ£ ì •ì±… ìš°ì„ ìˆœìœ„")
    print("=" * 60)
    print("ğŸ¥‡ 1ìˆœìœ„: 5km ì´ìƒ ì§€ì—­ (ì‚¬ê°ì§€ëŒ€)")
    print("   - ë‹¨ì† ê±´ìˆ˜: {:,}ê±´".format(distance_stats.loc['5kmì´ìƒ', ('ê±°ë¦¬_km', 'count')]))
    print("   - ìœ ì˜ˆì‹œê°„: 2.5ì‹œê°„")
    print("   - ì˜ˆìƒ íš¨ê³¼: 35% ë‹¨ì† ê°ì†Œ")
    print()
    print("ğŸ¥ˆ 2ìˆœìœ„: 3-5km ì§€ì—­")
    print("   - ë‹¨ì† ê±´ìˆ˜: {:,}ê±´".format(distance_stats.loc['3-5km', ('ê±°ë¦¬_km', 'count')]))
    print("   - ìœ ì˜ˆì‹œê°„: 2ì‹œê°„")
    print("   - ì˜ˆìƒ íš¨ê³¼: 30% ë‹¨ì† ê°ì†Œ")
    print()
    print("ğŸ¥‰ 3ìˆœìœ„: 2-3km ì§€ì—­")
    print("   - ë‹¨ì† ê±´ìˆ˜: {:,}ê±´".format(distance_stats.loc['2-3km', ('ê±°ë¦¬_km', 'count')]))
    print("   - ìœ ì˜ˆì‹œê°„: 1.5ì‹œê°„")
    print("   - ì˜ˆìƒ íš¨ê³¼: 25% ë‹¨ì† ê°ì†Œ")
    
    # 4. ì¢…í•© íš¨ê³¼ ì˜ˆì¸¡
    print("\n4ï¸âƒ£ ì¢…í•© íš¨ê³¼ ì˜ˆì¸¡")
    print("=" * 60)
    total_violations = distance_stats[('ê±°ë¦¬_km', 'count')].sum()
    weighted_reduction = 0
    
    for distance_range in distance_stats.index:
        count = distance_stats.loc[distance_range, ('ê±°ë¦¬_km', 'count')]
        weight = count / total_violations
        
        if distance_range == '0.5kmì´ë‚´':
            reduction = 0.1
        elif distance_range == '0.5-1km':
            reduction = 0.15
        elif distance_range == '1-2km':
            reduction = 0.2
        elif distance_range == '2-3km':
            reduction = 0.25
        elif distance_range == '3-5km':
            reduction = 0.3
        else:  # 5kmì´ìƒ
            reduction = 0.35
        
        weighted_reduction += weight * reduction
    
    print(f"ì „ì²´ ë‹¨ì† ê±´ìˆ˜: {total_violations:,}ê±´")
    print(f"ê°€ì¤‘ í‰ê·  ê°ì†Œìœ¨: {weighted_reduction*100:.1f}%")
    print(f"ì˜ˆìƒ ê°ì†Œ ê±´ìˆ˜: {total_violations * weighted_reduction:,.0f}ê±´")
    print(f"ì˜ˆìƒ ì ˆì•½ ë¹„ìš©: {total_violations * weighted_reduction * 10000:,.0f}ì› (ë‹¨ì†ë¹„ìš© 1ë§Œì› ê¸°ì¤€)")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== ê°€ì„¤ 1: ê³µì˜ì£¼ì°¨ì¥ ì ‘ê·¼ì„± ê¸°ë°˜ ë§ì¶¤í˜• ì •ì±… ===")
    print("ê±°ë¦¬ ê¸°ë°˜ ì‹¬í™” ë¶„ì„ ì‹œì‘\n")
    
    # ë°ì´í„° ë¡œë“œ
    distance_df, violations_df, parking_coords = load_data()
    
    # ê±°ë¦¬ íŒ¨í„´ ë¶„ì„
    distance_analysis, parking_analysis = analyze_distance_patterns(distance_df)
    
    # í•«ìŠ¤íŒŸ ë¶„ì„
    distance_violations, hotspot_analysis = analyze_hotspots_by_distance(distance_df, violations_df)
    
    # ì‚¬ê°ì§€ëŒ€ ë¶„ì„
    parking_deserts = analyze_parking_deserts(distance_df, parking_coords)
    
    # ê±°ë¦¬ ê¸°ë°˜ ì •ì±… ì œì•ˆ
    distance_policy, distance_stats = create_distance_based_policy(distance_df, violations_df)
    
    # í–¥ìƒëœ ì‹œê°í™” ìƒì„±
    create_enhanced_visualizations(distance_df, distance_violations, parking_deserts)
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    generate_comprehensive_report(distance_analysis, parking_analysis, hotspot_analysis, 
                                parking_deserts, distance_policy, distance_stats)
    
    print("\n=== âœ… ê±°ë¦¬ ê¸°ë°˜ ì‹¬í™” ë¶„ì„ ì™„ë£Œ ===")
    print("ìƒì„±ëœ íŒŒì¼:")
    print("- ê±°ë¦¬_ê¸°ë°˜_ì‹¬í™”ë¶„ì„.png")

if __name__ == "__main__":
    main()
