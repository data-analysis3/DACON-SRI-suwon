{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66064ad6",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d74ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wonny\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)  # ë°˜ë“œì‹œ ...\\envs\\geo_hotspot2\\python.exe ì—¬ì•¼ í•¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f92816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20ddcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8714a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7645dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e2eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aad6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, textwrap\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pyproj import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdd956a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import KNN, DistanceBand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b158b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48953a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b0233d",
   "metadata": {},
   "source": [
    "### ê²½ê¸°ë„ ìƒê¶Œ ë§¤ì¶œ ë°ì´í„° ìˆ˜ì§‘ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c6ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ì´ ê±´ìˆ˜: 69,194 / ì´ í˜ì´ì§€: 70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     df_all \u001b[38;5;241m=\u001b[39m fetch_all(psize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, sleep_sec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_all\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_all\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[12], line 61\u001b[0m, in \u001b[0;36mfetch_all\u001b[1;34m(psize, sleep_sec)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, total_pages \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m         payload \u001b[38;5;241m=\u001b[39m call_api(page\u001b[38;5;241m=\u001b[39mpage, psize\u001b[38;5;241m=\u001b[39mpsize)\n\u001b[0;32m     62\u001b[0m         rows \u001b[38;5;241m=\u001b[39m extract_rows(payload)\n\u001b[0;32m     63\u001b[0m         all_rows\u001b[38;5;241m.\u001b[39mextend(rows)\n",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m, in \u001b[0;36mcall_api\u001b[1;34m(page, psize)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ë‹¨ì¼ í˜ì´ì§€ í˜¸ì¶œ\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKEY\u001b[39m\u001b[38;5;124m\"\u001b[39m: API_KEY,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m: page,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpSize\u001b[39m\u001b[38;5;124m\"\u001b[39m: psize\n\u001b[0;32m     14\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(BASE_URL, params\u001b[38;5;241m=\u001b[39mparams, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     16\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 745\u001b[0m     r\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_chunk_length()\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m    759\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\wonny\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://openapi.gg.go.kr/TBGGESTDEVALLSTM\"\n",
    "API_KEY  = \"\" \n",
    "\n",
    "P_SIZE   = 1000\n",
    "SLEEP    = 0.2  # ê° í˜¸ì¶œ ì‚¬ì´ ëŒ€ê¸°(ì´ˆ) - ì„œë²„ ê³¼ë¶€í•˜/ì°¨ë‹¨ ì˜ˆë°©\n",
    "\n",
    "def call_api(page: int, psize: int = P_SIZE) -> dict:\n",
    "    \"\"\"ë‹¨ì¼ í˜ì´ì§€ í˜¸ì¶œ\"\"\"\n",
    "    params = {\n",
    "        \"KEY\": API_KEY,\n",
    "        \"Type\": \"json\",\n",
    "        \"pIndex\": page,\n",
    "        \"pSize\": psize\n",
    "    }\n",
    "    r = requests.get(BASE_URL, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def extract_total_count(payload: dict) -> int:\n",
    "    \"\"\"ì‘ë‹µì—ì„œ ì „ì²´ ê±´ìˆ˜ ì¶”ì¶œ (ëŒ€/ì†Œë¬¸ì ì„ì„ ë°©ì§€)\"\"\"\n",
    "    root = payload.get(\"TBGGESTDEVALLSTM\", [])\n",
    "    if not root:\n",
    "        raise ValueError(\"ì‘ë‹µì— 'TBGGESTDEVALLSTM' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    head = root[0].get(\"head\", [])\n",
    "    if not head:\n",
    "        raise ValueError(\"ì‘ë‹µì— 'head' ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    # ë³´í†µ head[0]ì— list_total_count, head[1].RESULTì— ì½”ë“œ/ë©”ì‹œì§€\n",
    "    h0 = head[0]\n",
    "    for k in (\"list_total_count\", \"LIST_TOTAL_COUNT\"):\n",
    "        if k in h0:\n",
    "            return int(h0[k])\n",
    "    # ê°„í˜¹ ë‹¤ë¥¸ ìœ„ì¹˜ì— ìˆì„ ê°€ëŠ¥ì„±ê¹Œì§€ ëŒ€ë¹„\n",
    "    for item in head:\n",
    "        for k in (\"list_total_count\", \"LIST_TOTAL_COUNT\"):\n",
    "            if k in item:\n",
    "                return int(item[k])\n",
    "    raise ValueError(\"ì „ì²´ ê±´ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "def extract_rows(payload: dict) -> list:\n",
    "    \"\"\"ì‘ë‹µì—ì„œ ë°ì´í„° í–‰(row) ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
    "    root = payload.get(\"TBGGESTDEVALLSTM\", [])\n",
    "    if len(root) < 2:\n",
    "        return []  # ë°ì´í„° ì—†ëŠ” í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ\n",
    "    rows = root[1].get(\"row\", [])\n",
    "    return rows or []\n",
    "\n",
    "def fetch_all(psize: int = P_SIZE, sleep_sec: float = SLEEP) -> pd.DataFrame:\n",
    "    \"\"\"ì „ì²´ í˜ì´ì§€ í¬ë¡¤ë§ â†’ DataFrame ë°˜í™˜\"\"\"\n",
    "    # 1) ì²« í˜ì´ì§€ë¡œ ì „ì²´ ê±´ìˆ˜ í™•ì¸\n",
    "    first = call_api(page=1, psize=psize)\n",
    "    total_count = extract_total_count(first)\n",
    "    total_pages = max(1, math.ceil(total_count / psize))\n",
    "    print(f\"[INFO] ì´ ê±´ìˆ˜: {total_count:,} / ì´ í˜ì´ì§€: {total_pages}\")\n",
    "\n",
    "    # 2) ì²« í˜ì´ì§€ rows ì ì¬\n",
    "    all_rows = extract_rows(first)\n",
    "\n",
    "    # 3) 2í˜ì´ì§€ë¶€í„° ë°˜ë³µ ìˆ˜ì§‘\n",
    "    for page in range(2, total_pages + 1):\n",
    "        try:\n",
    "            payload = call_api(page=page, psize=psize)\n",
    "            rows = extract_rows(payload)\n",
    "            all_rows.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] pIndex={page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    # 4) DataFrame ë³€í™˜\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    # (ì„ íƒ) ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬: ë¬¸ì„œì— ë‚˜ì˜¨ ëŒ€í‘œ ì»¬ëŸ¼ë“¤ì´ ìˆìœ¼ë©´ ì•ìœ¼ë¡œ ë°°ì¹˜\n",
    "    preferred_cols = [\n",
    "        \"STD_YY\",\"QU_NM\",\"DIV\",\"BIZDIST_NM\",\"CLASS_CD\",\"CLASS_CD_NM\",\"AMT\",\"NOC\",\n",
    "        \"API_VERSION\",\"CODE\",\"MESSAGE\"\n",
    "    ]\n",
    "    cols = [c for c in preferred_cols if c in df.columns] + [c for c in df.columns if c not in preferred_cols]\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_all = fetch_all(psize=1000, sleep_sec=0.2)\n",
    "    print(df_all.shape)\n",
    "    print(df_all.head())\n",
    "\n",
    "    # CSV ì €ì¥ (íŒŒì¼ëª…ì€ ììœ ë¡­ê²Œ ë³€ê²½)\n",
    "    out_path = \"ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ.csv\"\n",
    "    df_all.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[DONE] ì €ì¥ì™„ë£Œ: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a746d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df335a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STD_YY</th>\n",
       "      <th>QU_NM</th>\n",
       "      <th>DIV</th>\n",
       "      <th>BIZDIST_NM</th>\n",
       "      <th>CLASS_CD</th>\n",
       "      <th>CLASS_CD_NM</th>\n",
       "      <th>AMT</th>\n",
       "      <th>NOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47591</td>\n",
       "      <td>ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…</td>\n",
       "      <td>2352809</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47592</td>\n",
       "      <td>ì£¼ë°©ìš©í’ˆ ë° ê°€ì •ìš© ìœ ë¦¬, ìš”ì—…ì œí’ˆ ì†Œë§¤ì—…</td>\n",
       "      <td>6969499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47611</td>\n",
       "      <td>ì„œì , ì‹ ë¬¸ ë° ì¡ì§€ë¥˜ ì†Œë§¤ì—…</td>\n",
       "      <td>45261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47631</td>\n",
       "      <td>ìš´ë™ ë° ê²½ê¸°ìš©í’ˆ ì†Œë§¤ì—…</td>\n",
       "      <td>5416628</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47632</td>\n",
       "      <td>ìì „ê±° ë° ê¸°íƒ€ ìš´ì†¡ì¥ë¹„ ì†Œë§¤ì—…</td>\n",
       "      <td>4762640</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69189</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47591</td>\n",
       "      <td>ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…</td>\n",
       "      <td>12616929</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69190</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47520</td>\n",
       "      <td>ê°€êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>2032093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69191</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47511</td>\n",
       "      <td>ì² ë¬¼ ë° ë‚œë°©ìš©êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>62150740</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69192</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47422</td>\n",
       "      <td>ì˜ë³µ ì•¡ì„¸ì„œë¦¬ ë° ëª¨ì¡° ì¥ì‹ êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>33922877</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69193</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47414</td>\n",
       "      <td>ì…”ì¸  ë° ë¸”ë¼ìš°ìŠ¤ ì†Œë§¤ì—…</td>\n",
       "      <td>40299634</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69194 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STD_YY  QU_NM   DIV BIZDIST_NM  CLASS_CD              CLASS_CD_NM  \\\n",
       "0        2024      3  1143        ì—¬ì–‘ë¡œ     47591          ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…   \n",
       "1        2024      3  1143        ì—¬ì–‘ë¡œ     47592  ì£¼ë°©ìš©í’ˆ ë° ê°€ì •ìš© ìœ ë¦¬, ìš”ì—…ì œí’ˆ ì†Œë§¤ì—…   \n",
       "2        2024      3  1143        ì—¬ì–‘ë¡œ     47611         ì„œì , ì‹ ë¬¸ ë° ì¡ì§€ë¥˜ ì†Œë§¤ì—…   \n",
       "3        2024      3  1143        ì—¬ì–‘ë¡œ     47631            ìš´ë™ ë° ê²½ê¸°ìš©í’ˆ ì†Œë§¤ì—…   \n",
       "4        2024      3  1143        ì—¬ì–‘ë¡œ     47632        ìì „ê±° ë° ê¸°íƒ€ ìš´ì†¡ì¥ë¹„ ì†Œë§¤ì—…   \n",
       "...       ...    ...   ...        ...       ...                      ...   \n",
       "69189    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47591          ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…   \n",
       "69190    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47520                   ê°€êµ¬ ì†Œë§¤ì—…   \n",
       "69191    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47511            ì² ë¬¼ ë° ë‚œë°©ìš©êµ¬ ì†Œë§¤ì—…   \n",
       "69192    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47422     ì˜ë³µ ì•¡ì„¸ì„œë¦¬ ë° ëª¨ì¡° ì¥ì‹ êµ¬ ì†Œë§¤ì—…   \n",
       "69193    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47414            ì…”ì¸  ë° ë¸”ë¼ìš°ìŠ¤ ì†Œë§¤ì—…   \n",
       "\n",
       "            AMT   NOC  \n",
       "0       2352809    36  \n",
       "1       6969499     5  \n",
       "2         45261     1  \n",
       "3       5416628    20  \n",
       "4       4762640    90  \n",
       "...         ...   ...  \n",
       "69189  12616929   202  \n",
       "69190   2032093     1  \n",
       "69191  62150740   239  \n",
       "69192  33922877   522  \n",
       "69193  40299634  1370  \n",
       "\n",
       "[69194 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c928067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BIZDIST_NM  CLASS_CD      AMT  NOC\n",
      "0        ì—¬ì–‘ë¡œ     47591  2352809   36\n",
      "1        ì—¬ì–‘ë¡œ     47592  6969499    5\n",
      "2        ì—¬ì–‘ë¡œ     47611    45261    1\n",
      "3        ì—¬ì–‘ë¡œ     47631  5416628   20\n",
      "4        ì—¬ì–‘ë¡œ     47632  4762640   90\n",
      "Index(['BIZDIST_NM', 'CLASS_CD', 'AMT', 'NOC'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°\n",
    "df.drop(columns=[\"STD_YY\", \"QU_NM\", \"DIV\", \"CLASS_CD_NM\"], inplace=True)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(df.head())\n",
    "print(df.columns)  # ë‚¨ì€ ì»¬ëŸ¼ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240961dc",
   "metadata": {},
   "source": [
    "### ìœ„ê²½ë„ ë§¤í•‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f840148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kakao API í‚¤ (ì¶”ì²œ: í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬)\n",
    "KAKAO_REST_KEY = os.getenv(\"KAKAO_REST_KEY\", \"\")\n",
    "KAKAO_JS_KEY   = os.getenv(\"KAKAO_JS_KEY\",   \"\")\n",
    "HEADERS = {\"Authorization\": f\"KakaoAK {KAKAO_REST_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055afaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ê¸°ë„ ì „ì²´ bbox (W,S,E,N)\n",
    "GG_RECT = \"126.60,36.90,127.80,38.30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì²´í¬í¬ì¸íŠ¸/ìºì‹œ/ìŠ¬ë¦½\n",
    "CHECKPOINT_EVERY = 50\n",
    "CHECKPOINT_PATH  = \"map_progress.csv\"     # ì§„í–‰ìƒí™© snapshot\n",
    "CACHE_PATH       = \"map_cache.json\"       # name -> {lon,lat,payload}\n",
    "FAILED_PATH      = \"failed_names.csv\"\n",
    "SLEEP_SEC        = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f984ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Geocoding BIZDIST_NM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1640/1640 [04:06<00:00,  6.66name/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ 1ì°¨ ì‹¤íŒ¨: 115ê°œ â†’ failed_names.csv ì €ì¥\n",
      "âœ… 1ì°¨ ë³‘í•© ì™„ë£Œ: ì´ 69194í–‰ / ì¢Œí‘œì„±ê³µ 64258í–‰ (92.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retry failed: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.15s/name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì¬ì‹œë„ ê²°ê³¼: ê³ ì³ì§ 0 / ì—¬ì „íˆ ì‹¤íŒ¨ 115\n",
      "ğŸ ìµœì¢… ì¢Œí‘œì„±ê³µ 64258 / 69194 (92.9%)\n",
      "ğŸ’¾ ì €ì¥: BIZDIST_with_coords.csv  /  ì§„í–‰ìŠ¤ëƒ…ìƒ·: map_progress.csv  / ìºì‹œ: map_cache.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ğŸ”§ 1) ìœ í‹¸\n",
    "# ============================================\n",
    "def load_cache(path: str) -> dict:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(path: str, cache: dict):\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, ensure_ascii=False)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def within_rect(lon: float, lat: float, rect: str = GG_RECT) -> bool:\n",
    "    W, S, E, N = map(float, rect.split(\",\"))\n",
    "    return (W <= lon <= E) and (S <= lat <= N)\n",
    "\n",
    "def _normalize_text(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = re.sub(r\"(ë³¸ì |ì§€ì |ì )$\", \"\", s)\n",
    "    s = re.sub(r\"[-_Â·â€¢ã†]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def _is_road_like(name: str) -> bool:\n",
    "    return bool(re.search(r\"(ê¸¸|ë¡œ|ëŒ€ë¡œ)$\", name))\n",
    "\n",
    "def _extract_city(addr: str) -> str | None:\n",
    "    if not addr: return None\n",
    "    parts = addr.split()\n",
    "    if len(parts) >= 2 and parts[0].startswith(\"ê²½ê¸°\"):\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "def guess_category(name: str) -> str | None:\n",
    "    s = str(name)\n",
    "    if re.search(r\"(ì´ˆë“±í•™êµ|ì¤‘í•™êµ|ê³ ë“±í•™êµ|í•™êµ)\", s): return \"SC4\"\n",
    "    if re.search(r\"(ì£¼ë¯¼ì„¼í„°|êµ¬ì²­|ì‹œì²­|í–‰ì •ë³µì§€ì„¼í„°|ë™ì‚¬ë¬´ì†Œ|ìš°ì²´êµ­|ìš°í¸ì·¨ê¸‰êµ­|ì·¨ê¸‰êµ­|ì†Œë°©ì„œ|ê²½ì°°ì„œ)\", s): return \"PO3\"\n",
    "    if re.search(r\"(ë³´ê±´ì†Œ|ë³‘ì›|ì˜ì›|ì¹˜ê³¼|í•œì˜ì›)\", s): return \"HP8\"\n",
    "    return None\n",
    "\n",
    "def is_in_gyeonggi(place: dict) -> bool:\n",
    "    for k in (\"road_address_name\", \"address_name\"):\n",
    "        v = (place.get(k) or \"\").strip()\n",
    "        if re.match(r\"^ê²½ê¸°(ë„)?(\\s|$)\", v):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸŒ 2) Kakao API ë˜í¼\n",
    "# ============================================\n",
    "def kakao_keyword_search(query: str, rect: str = GG_RECT, category: str | None = None, size: int = 10) -> list[dict]:\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/keyword.json\"\n",
    "    params = {\"query\": query, \"rect\": rect, \"size\": size}\n",
    "    if category:\n",
    "        params[\"category_group_code\"] = category\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params, timeout=5)\n",
    "            if r.status_code == 200:\n",
    "                return r.json().get(\"documents\", [])\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        time.sleep(0.25 + 0.25*attempt)\n",
    "    return []\n",
    "\n",
    "def kakao_address_search(query: str, size: int = 10) -> list[dict]:\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/address.json\"\n",
    "    params = {\"query\": query, \"size\": size}\n",
    "    for attempt in range(2):\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params, timeout=5)\n",
    "            if r.status_code == 200:\n",
    "                return r.json().get(\"documents\", [])\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        time.sleep(0.25 + 0.25*attempt)\n",
    "    return []\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸ§  3) ì‹¤íŒ¨íŒ¨í„´ êµì •(ì •ê·œí™”) + ë™ì˜ì–´ ë³´ì •\n",
    "# ============================================\n",
    "ALIAS = {\n",
    "    # ì—­ ì¶œêµ¬ ì–¸ë”ìŠ¤ì½”ì–´\n",
    "    \"ë¶€ì²œì‹œì²­ì—­_1ë²ˆì¶œêµ¬\": \"ë¶€ì²œì‹œì²­ì—­ 1ë²ˆì¶œêµ¬\",\n",
    "    \"ë¶€ì²œì‹œì²­ì—­_3ë²ˆì¶œêµ¬\": \"ë¶€ì²œì‹œì²­ì—­ 3ë²ˆì¶œêµ¬\",\n",
    "    \"ë¶€ì²œì‹œì²­ì—­_4ë²ˆì¶œêµ¬\": \"ë¶€ì²œì‹œì²­ì—­ 4ë²ˆì¶œêµ¬\",\n",
    "    \"ìˆ˜ì›ì‹œì²­ì—­_1ë²ˆì¶œêµ¬\": \"ìˆ˜ì›ì‹œì²­ì—­ 1ë²ˆì¶œêµ¬\",\n",
    "    \"ìˆ˜ì›ì‹œì²­ì—­_7ë²ˆì¶œêµ¬\": \"ìˆ˜ì›ì‹œì²­ì—­ 7ë²ˆì¶œêµ¬\",\n",
    "    # ë„ë¡œëª…+ë²ˆê¸¸ ê³µë°±\n",
    "    \"ê²½ì˜ë¡œ146ë²ˆê¸¸\": \"ê²½ì˜ë¡œ 146ë²ˆê¸¸\",\n",
    "    \"ì„œì•”ë¡œ6ë²ˆê¸¸\":  \"ì„œì•”ë¡œ 6ë²ˆê¸¸\",\n",
    "    \"ìš´ì¤‘ë¡œ267ë²ˆê¸¸\": \"ìš´ì¤‘ë¡œ 267ë²ˆê¸¸\",\n",
    "    # ê¸°íƒ€ ì˜¤íƒ€/ë„ì–´ì“°ê¸°\n",
    "    \"ë‰´í”„ë¦°ìŠ¤ê´€ê´‘í˜¸í…”\": \"í”„ë¦°ìŠ¤ê´€ê´‘í˜¸í…”\",\n",
    "    \"ë¡¯ë°ì• ë¹„ë‰´ì—˜ì•ˆì‚°ì \": \"ë¡¯ë° ì—ë¹„ë‰´ì—˜ ì•ˆì‚°ì \",\n",
    "    \"ë¡¯ë°ì• ë¹„ë‰´ì—˜ì¼ì‚°ì \": \"ë¡¯ë° ì—ë¹„ë‰´ì—˜ ì¼ì‚°ì \",\n",
    "    \"ë¡¯ë°ë§ˆíŠ¸ë¹…ë§ˆì¼“í‚¨í…ìŠ¤ì \": \"ë¡¯ë°ë§ˆíŠ¸ ë¹…ë§ˆì¼“ í‚¨í…ìŠ¤ì \",\n",
    "    \"í™ˆí”ŒëŸ¬ìŠ¤ì˜ì „ë¶€ì \": \"í™ˆí”ŒëŸ¬ìŠ¤ ì˜ì •ë¶€ì \",\n",
    "}\n",
    "\n",
    "SYNONYM_RULES = [\n",
    "    (r\"ì •ë¥˜ì†Œ$\", \"ì •ë¥˜ì¥\"),\n",
    "    (r\"ê³µìš©ë²„ìŠ¤í„°ë¯¸ë„$\", \"ë²„ìŠ¤í„°ë¯¸ë„\"),\n",
    "    (r\"ì—­_?(\\d+)ë²ˆì¶œêµ¬$\", r\"ì—­ \\1ë²ˆì¶œêµ¬\"),\n",
    "]\n",
    "\n",
    "def insert_spaces_for_admin(s: str) -> str:\n",
    "    s = re.sub(r\"^([ê°€-í£]+)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ìš°ì²´êµ­$\",     r\"\\1 \\2 ìš°ì²´êµ­\", s)\n",
    "    s = re.sub(r\"^([ê°€-í£]+)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ì •ë¥˜ì¥$\",     r\"\\1 \\2 ì •ë¥˜ì¥\", s)\n",
    "    s = re.sub(r\"^([ê°€-í£]+)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ë²„ìŠ¤í„°ë¯¸ë„$\", r\"\\1 \\2 ë²„ìŠ¤í„°ë¯¸ë„\", s)\n",
    "    s = re.sub(r\"^([ê°€-í£]+)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ì—­(\\s*\\d+ë²ˆì¶œêµ¬)?$\", r\"\\1 \\2 ì—­\\4\", s)\n",
    "    return s\n",
    "\n",
    "def space_road_bn(s: str) -> str:\n",
    "    s = re.sub(r\"(ë¡œ|ê¸¸|ëŒ€ë¡œ)(\\d+)ë²ˆê¸¸$\", r\"\\1 \\2ë²ˆê¸¸\", s)\n",
    "    s = re.sub(r\"(ë¡œ|ê¸¸|ëŒ€ë¡œ)(\\d+)$\",     r\"\\1 \\2\", s)\n",
    "    return s\n",
    "\n",
    "def normalize_candidates(name: str) -> list[str]:\n",
    "    base = name.strip()\n",
    "    outs = []\n",
    "    def push(x): \n",
    "        x = x.strip()\n",
    "        if x and x not in outs: outs.append(x)\n",
    "\n",
    "    if base in ALIAS: push(ALIAS[base])\n",
    "\n",
    "    n1 = re.sub(r\"_[0-9]+$\", \"\", base)                          # ì ‘ë¯¸ _ìˆ«ì ì œê±°\n",
    "    n2 = re.sub(r\"ì—­_([0-9]+)ë²ˆì¶œêµ¬$\", r\"ì—­ \\1ë²ˆì¶œêµ¬\", n1)        # ì—­_ì¶œêµ¬ â†’ ê³µë°±\n",
    "    n3 = space_road_bn(n2)                                       # ë„ë¡œëª…+ë²ˆê¸¸ ê³µë°±\n",
    "    n4 = insert_spaces_for_admin(n3)                             # í–‰ì •ë™/ì/ë©´/ë¦¬ ë„ì–´ì“°ê¸°\n",
    "    n5 = n4\n",
    "    for pat, repl in SYNONYM_RULES: n5 = re.sub(pat, repl, n5)   # ë™ì˜ì–´\n",
    "\n",
    "    # ìš°ì²´êµ­ -> ìš°í¸ì·¨ê¸‰êµ­/ì·¨ê¸‰êµ­ ë³€í˜•ë„ ì‹œë„\n",
    "    if n5.endswith(\"ìš°ì²´êµ­\"):\n",
    "        push(n5.replace(\"ìš°ì²´êµ­\", \"ìš°í¸ì·¨ê¸‰êµ­\"))\n",
    "        push(n5.replace(\"ìš°ì²´êµ­\", \"ì·¨ê¸‰êµ­\"))\n",
    "\n",
    "    # ì§€ì—­ íŒíŠ¸ ì¶”ê°€ í›„ë³´\n",
    "    for x in [base, n1, n2, n3, n4, n5]:\n",
    "        push(x)\n",
    "    push(\"ê²½ê¸° \" + n5)\n",
    "    push(\"ê²½ê¸°ë„ \" + n5)\n",
    "    return outs\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸ§­ 4) í•µì‹¬: ì§€ì˜¤ì½”ë”© í•¨ìˆ˜(ë³´ì •/ë‹¤ì¤‘í›„ë³´/ë„ë¡œëª…ì—„ê²©)\n",
    "# ============================================\n",
    "STRICT_ROAD_NAMES = {\"ë²šê½ƒê¸¸\"}\n",
    "ROAD_SCORE_THRESHOLD   = 75\n",
    "STRICT_SCORE_THRESHOLD = 85\n",
    "\n",
    "def geocode_one(name: str, retry_sleep: float = 0.25):\n",
    "    name = str(name).strip()\n",
    "    if not name:\n",
    "        return None, None, None\n",
    "\n",
    "    queries = normalize_candidates(name)\n",
    "    for q in queries:\n",
    "        cat = guess_category(q)\n",
    "        road_like  = _is_road_like(q)\n",
    "        strict_mode = q in STRICT_ROAD_NAMES\n",
    "\n",
    "        # 1) í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "        docs = kakao_keyword_search(q, rect=GG_RECT, category=cat, size=10)\n",
    "        if not docs:\n",
    "            # ë„ë¡œëª…ì¼ ë•Œ ì£¼ì†Œê²€ìƒ‰ fallback\n",
    "            if road_like:\n",
    "                addrs = kakao_address_search(q, size=10)\n",
    "                addr_docs = []\n",
    "                for a in addrs:\n",
    "                    region1 = (a.get(\"address\", {}) or {}).get(\"region_1depth_name\") or \\\n",
    "                              (a.get(\"road_address\", {}) or {}).get(\"region_1depth_name\")\n",
    "                    x = a.get(\"x\"); y = a.get(\"y\")\n",
    "                    if region1 == \"ê²½ê¸°\" and x and y and within_rect(float(x), float(y), GG_RECT):\n",
    "                        addr_docs.append({\n",
    "                            \"x\": x, \"y\": y, \"place_name\": q,\n",
    "                            \"address_name\": (a.get(\"address\", {}) or {}).get(\"address_name\"),\n",
    "                            \"road_address_name\": (a.get(\"road_address\", {}) or {}).get(\"address_name\")\n",
    "                        })\n",
    "                if addr_docs:\n",
    "                    best = addr_docs[0]\n",
    "                    return float(best[\"x\"]), float(best[\"y\"]), best\n",
    "            time.sleep(retry_sleep)\n",
    "            continue\n",
    "\n",
    "        # 2) ê²½ê¸°ë„ ìš°ì„ \n",
    "        candidates = [d for d in docs if is_in_gyeonggi(d)] or docs\n",
    "        if not candidates:\n",
    "            time.sleep(retry_sleep); continue\n",
    "\n",
    "        # 3) ë„ë¡œëª…ì´ë©´ road_address í¬í•¨ í›„ë³´ ìš°ì„ \n",
    "        if road_like:\n",
    "            road_pat = re.compile(rf'(?<![ê°€-í£0-9]){re.escape(q)}(?![ê°€-í£])')\n",
    "            c_road = [d for d in candidates if road_pat.search(d.get(\"road_address_name\") or \"\")]\n",
    "            if c_road: \n",
    "                candidates = c_road\n",
    "            else:\n",
    "                c_addr = [d for d in candidates if road_pat.search(d.get(\"address_name\") or \"\")]\n",
    "                if c_addr: \n",
    "                    candidates = c_addr\n",
    "\n",
    "        # 4) ìŠ¤ì½”ì–´\n",
    "        n_q = _normalize_text(q)\n",
    "        def score(d: dict) -> int:\n",
    "            pname = (d.get(\"place_name\") or \"\").strip()\n",
    "            n_p = _normalize_text(pname)\n",
    "            ra = (d.get(\"road_address_name\") or \"\")\n",
    "            aa = (d.get(\"address_name\") or \"\")\n",
    "            s = 0\n",
    "            if n_p == n_q: s = 100\n",
    "            elif n_q in n_p or n_p in n_q: s = 80\n",
    "            else: s = int(SequenceMatcher(None, n_p, n_q).ratio() * 75)\n",
    "\n",
    "            # 'ê²½ê¸°' ì ‘ë‘ ë³´ë„ˆìŠ¤\n",
    "            if re.match(r\"^ê²½ê¸°(ë„)?(\\s|$)\", ra) or re.match(r\"^ê²½ê¸°(ë„)?(\\s|$)\", aa):\n",
    "                s += 5\n",
    "\n",
    "            # ë„ë¡œëª… ê°€ì¤‘ì¹˜\n",
    "            if road_like:\n",
    "                road_pat = re.compile(rf'(?<![ê°€-í£0-9]){re.escape(q)}(?![ê°€-í£])')\n",
    "                in_road = bool(road_pat.search(ra))\n",
    "                in_addr = bool(road_pat.search(aa))\n",
    "                if in_road: s += 25\n",
    "                elif in_addr: s += 5; s -= 10\n",
    "                else: s -= 30\n",
    "\n",
    "            # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤(POIë¥˜)\n",
    "            key_bonus = 0\n",
    "            if re.search(r\"ìš°ì²´êµ­|ìš°í¸ì·¨ê¸‰êµ­|ì·¨ê¸‰êµ­\", q): key_bonus += 10\n",
    "            if re.search(r\"ì •ë¥˜ì¥|ë²„ìŠ¤í„°ë¯¸ë„|í„°ë¯¸ë„\", q): key_bonus += 8\n",
    "            if re.search(r\"ì—­\\s*\\d+ë²ˆì¶œêµ¬|ì—­$\", q): key_bonus += 6\n",
    "            if re.search(r\"ì‹œì¥\", q): key_bonus += 5\n",
    "            if re.search(r\"í˜¸í…”|ë§ˆíŠ¸|ê°¤ëŸ¬ë¦¬|ì „ì‹œê´€|ì—ë¹„ë‰´ì—˜\", q, re.I): key_bonus += 4\n",
    "            s += key_bonus\n",
    "            return s\n",
    "\n",
    "        best = max(candidates, key=score)\n",
    "        try:\n",
    "            lon = float(best[\"x\"]); lat = float(best[\"y\"])\n",
    "        except (KeyError, ValueError, TypeError):\n",
    "            time.sleep(retry_sleep); continue\n",
    "\n",
    "        # 5) ë„ë¡œëª… ìµœì¢… ê²€ì¦/ë³´ì •\n",
    "        if road_like:\n",
    "            road_pat = re.compile(rf'(?<![ê°€-í£0-9]){re.escape(q)}(?![ê°€-í£])')\n",
    "            ra = (best.get(\"road_address_name\") or \"\")\n",
    "            sc = score(best)\n",
    "            if q in STRICT_ROAD_NAMES:\n",
    "                if not road_pat.search(ra) or sc < STRICT_SCORE_THRESHOLD:\n",
    "                    time.sleep(retry_sleep); continue\n",
    "            else:\n",
    "                if sc < ROAD_SCORE_THRESHOLD:\n",
    "                    time.sleep(retry_sleep); continue\n",
    "\n",
    "            if not road_pat.search(ra):\n",
    "                # address APIë¡œ ë³´ì • ì‹œë„\n",
    "                addrs = kakao_address_search(q, size=10)\n",
    "                for a in addrs:\n",
    "                    region1 = (a.get(\"address\", {}) or {}).get(\"region_1depth_name\") or \\\n",
    "                              (a.get(\"road_address\", {}) or {}).get(\"region_1depth_name\")\n",
    "                    x = a.get(\"x\"); y = a.get(\"y\")\n",
    "                    ra2 = (a.get(\"road_address\", {}) or {}).get(\"address_name\") or \"\"\n",
    "                    if region1 == \"ê²½ê¸°\" and x and y and within_rect(float(x), float(y), GG_RECT) and road_pat.search(ra2):\n",
    "                        return float(x), float(y), {\n",
    "                            \"place_name\": q,\n",
    "                            \"address_name\": (a.get(\"address\", {}) or {}).get(\"address_name\"),\n",
    "                            \"road_address_name\": ra2,\n",
    "                            \"x\": x, \"y\": y\n",
    "                        }\n",
    "\n",
    "        # 6) BBOX í™•ì¸\n",
    "        if within_rect(lon, lat, GG_RECT):\n",
    "            return lon, lat, best\n",
    "\n",
    "        time.sleep(retry_sleep)\n",
    "\n",
    "    # ëª¨ë‘ ì‹¤íŒ¨\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸš€ 5) 1ì°¨ ì‹¤í–‰: ìœ ë‹ˆí¬ ì§€ëª… â†’ ì¢Œí‘œ ë§¤í•‘\n",
    "# ============================================\n",
    "unique_names = (\n",
    "    df[\"BIZDIST_NM\"]\n",
    "    .astype(str).str.strip()\n",
    "    .replace({\"nan\": None})\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "cache  = load_cache(CACHE_PATH)   # {name: {lon,lat,payload}}\n",
    "rows   = []\n",
    "failed = []\n",
    "\n",
    "try:\n",
    "    for i, name in enumerate(tqdm(unique_names, desc=\"Geocoding BIZDIST_NM\", unit=\"name\"), start=1):\n",
    "        # ìºì‹œ íˆíŠ¸\n",
    "        if name in cache and cache[name].get(\"lon\") is not None and cache[name].get(\"lat\") is not None:\n",
    "            item = cache[name]\n",
    "            lon, lat, payload = item[\"lon\"], item[\"lat\"], item.get(\"payload\")\n",
    "        else:\n",
    "            lon, lat, payload = geocode_one(name)\n",
    "            cache[name] = {\"lon\": lon, \"lat\": lat, \"payload\": payload}\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "        rows.append({\"BIZDIST_NM\": name, \"lon\": lon, \"lat\": lat, \"meta\": payload})\n",
    "        if (lon is None) or (lat is None):\n",
    "            failed.append(name)\n",
    "\n",
    "        if i % CHECKPOINT_EVERY == 0:\n",
    "            pd.DataFrame(rows).to_csv(CHECKPOINT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "            save_cache(CACHE_PATH, cache)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâ›”ï¸ ì¤‘ë‹¨ ê°ì§€: ì§„í–‰ë¶„ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "finally:\n",
    "    map_df = pd.DataFrame(rows)\n",
    "    map_df.to_csv(CHECKPOINT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    save_cache(CACHE_PATH, cache)\n",
    "    if failed:\n",
    "        pd.DataFrame({\"BIZDIST_NM\": sorted(set(failed))}).to_csv(FAILED_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"âŒ 1ì°¨ ì‹¤íŒ¨: {len(set(failed))}ê°œ â†’ {FAILED_PATH} ì €ì¥\")\n",
    "\n",
    "# ë³‘í•©(ì›ë³¸ dfì— lon/lat/meta ì¶”ê°€)\n",
    "df = df.merge(map_df, on=\"BIZDIST_NM\", how=\"left\")\n",
    "print(f\"âœ… 1ì°¨ ë³‘í•© ì™„ë£Œ: ì´ {len(df)}í–‰ / ì¢Œí‘œì„±ê³µ {df['lon'].notna().sum()}í–‰ ({df['lon'].notna().mean():.1%})\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ğŸ” 6) 2ì°¨: ì‹¤íŒ¨ëª©ë¡ ì¬ì‹œë„(ë³´ì • í¬í•¨ geocode_one ì‚¬ìš©)\n",
    "# ============================================\n",
    "def retry_failed_names(failed_csv=FAILED_PATH, sleep=0.35):\n",
    "    if not os.path.exists(failed_csv):\n",
    "        print(\"â­ ì¬ì‹œë„ ìŠ¤í‚µ: ì‹¤íŒ¨ ëª©ë¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame()\n",
    "    fnames = pd.read_csv(failed_csv, encoding=\"utf-8-sig\")[\"BIZDIST_NM\"].astype(str).tolist()\n",
    "    rows2, still = [], []\n",
    "    for nm in tqdm(fnames, desc=\"Retry failed\", unit=\"name\"):\n",
    "        lon, lat, payload = geocode_one(nm, retry_sleep=sleep)\n",
    "        if lon is not None and lat is not None:\n",
    "            rows2.append({\"BIZDIST_NM\": nm, \"lon\": lon, \"lat\": lat, \"meta\": payload})\n",
    "        else:\n",
    "            still.append(nm)\n",
    "    fixed_df = pd.DataFrame(rows2)\n",
    "    if not fixed_df.empty:\n",
    "        fixed_df.to_csv(\"failed_fixed.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    if still:\n",
    "        pd.DataFrame({\"BIZDIST_NM\": still}).to_csv(\"failed_still.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ” ì¬ì‹œë„ ê²°ê³¼: ê³ ì³ì§ {len(rows2)} / ì—¬ì „íˆ ì‹¤íŒ¨ {len(still)}\")\n",
    "    return fixed_df\n",
    "\n",
    "fixed_df = retry_failed_names(FAILED_PATH, sleep=0.35)\n",
    "\n",
    "# ê³ ì³ì§„ ê²°ê³¼ë¥¼ dfì— ë®ì–´ì“°ê¸°\n",
    "if not fixed_df.empty:\n",
    "    # ìš°ì„  map_dfë„ ì—…ë°ì´íŠ¸(ë¡œê·¸/ì¬ì‚¬ìš© ìœ„í•´)\n",
    "    map_df_fixed = map_df.drop(columns=[\"lon\",\"lat\",\"meta\"], errors=\"ignore\") \\\n",
    "                         .merge(fixed_df, on=\"BIZDIST_NM\", how=\"left\", suffixes=(\"\",\"_new\"))\n",
    "    # ì›ë˜ ì„±ê³µê°’ì€ ë³´ì¡´, NaNë§Œ ì±„ìš°ê¸°\n",
    "    map_df[\"lon\"]  = map_df[\"lon\"].fillna(map_df_fixed[\"lon\"])\n",
    "    map_df[\"lat\"]  = map_df[\"lat\"].fillna(map_df_fixed[\"lat\"])\n",
    "    map_df[\"meta\"] = map_df[\"meta\"].where(map_df[\"meta\"].notna(), map_df_fixed[\"meta\"])\n",
    "\n",
    "    # ì›ë³¸ df ê°±ì‹ \n",
    "    df = df.drop(columns=[\"lon\",\"lat\",\"meta\"], errors=\"ignore\") \\\n",
    "           .merge(map_df, on=\"BIZDIST_NM\", how=\"left\")\n",
    "\n",
    "print(f\"ğŸ ìµœì¢… ì¢Œí‘œì„±ê³µ {df['lon'].notna().sum()} / {len(df)} ({df['lon'].notna().mean():.1%})\")\n",
    "\n",
    "# (ì„ íƒ) ìµœì¢… ì €ì¥\n",
    "df.to_csv(\"ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ_ìœ„ê²½ë„(1).csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ’¾ ì €ì¥: ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ_ìœ„ê²½ë„(1).csv  /  ì§„í–‰ìŠ¤ëƒ…ìƒ·:\", CHECKPOINT_PATH, \" / ìºì‹œ:\", CACHE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92ae2f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STD_YY</th>\n",
       "      <th>QU_NM</th>\n",
       "      <th>DIV</th>\n",
       "      <th>BIZDIST_NM</th>\n",
       "      <th>CLASS_CD</th>\n",
       "      <th>CLASS_CD_NM</th>\n",
       "      <th>AMT</th>\n",
       "      <th>NOC</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47591</td>\n",
       "      <td>ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…</td>\n",
       "      <td>2352809</td>\n",
       "      <td>36</td>\n",
       "      <td>127.605348</td>\n",
       "      <td>37.356399</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47592</td>\n",
       "      <td>ì£¼ë°©ìš©í’ˆ ë° ê°€ì •ìš© ìœ ë¦¬, ìš”ì—…ì œí’ˆ ì†Œë§¤ì—…</td>\n",
       "      <td>6969499</td>\n",
       "      <td>5</td>\n",
       "      <td>127.605348</td>\n",
       "      <td>37.356399</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47611</td>\n",
       "      <td>ì„œì , ì‹ ë¬¸ ë° ì¡ì§€ë¥˜ ì†Œë§¤ì—…</td>\n",
       "      <td>45261</td>\n",
       "      <td>1</td>\n",
       "      <td>127.605348</td>\n",
       "      <td>37.356399</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47631</td>\n",
       "      <td>ìš´ë™ ë° ê²½ê¸°ìš©í’ˆ ì†Œë§¤ì—…</td>\n",
       "      <td>5416628</td>\n",
       "      <td>20</td>\n",
       "      <td>127.605348</td>\n",
       "      <td>37.356399</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1143</td>\n",
       "      <td>ì—¬ì–‘ë¡œ</td>\n",
       "      <td>47632</td>\n",
       "      <td>ìì „ê±° ë° ê¸°íƒ€ ìš´ì†¡ì¥ë¹„ ì†Œë§¤ì—…</td>\n",
       "      <td>4762640</td>\n",
       "      <td>90</td>\n",
       "      <td>127.605348</td>\n",
       "      <td>37.356399</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69189</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47591</td>\n",
       "      <td>ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…</td>\n",
       "      <td>12616929</td>\n",
       "      <td>202</td>\n",
       "      <td>126.798050</td>\n",
       "      <td>37.444513</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69190</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47520</td>\n",
       "      <td>ê°€êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>2032093</td>\n",
       "      <td>1</td>\n",
       "      <td>126.798050</td>\n",
       "      <td>37.444513</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69191</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47511</td>\n",
       "      <td>ì² ë¬¼ ë° ë‚œë°©ìš©êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>62150740</td>\n",
       "      <td>239</td>\n",
       "      <td>126.798050</td>\n",
       "      <td>37.444513</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69192</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47422</td>\n",
       "      <td>ì˜ë³µ ì•¡ì„¸ì„œë¦¬ ë° ëª¨ì¡° ì¥ì‹ êµ¬ ì†Œë§¤ì—…</td>\n",
       "      <td>33922877</td>\n",
       "      <td>522</td>\n",
       "      <td>126.798050</td>\n",
       "      <td>37.444513</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69193</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1648</td>\n",
       "      <td>ì˜¬ë ˆí”Œë¼ìì‹œí¥ì </td>\n",
       "      <td>47414</td>\n",
       "      <td>ì…”ì¸  ë° ë¸”ë¼ìš°ìŠ¤ ì†Œë§¤ì—…</td>\n",
       "      <td>40299634</td>\n",
       "      <td>1370</td>\n",
       "      <td>126.798050</td>\n",
       "      <td>37.444513</td>\n",
       "      <td>{'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69194 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STD_YY  QU_NM   DIV BIZDIST_NM  CLASS_CD              CLASS_CD_NM  \\\n",
       "0        2024      3  1143        ì—¬ì–‘ë¡œ     47591          ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…   \n",
       "1        2024      3  1143        ì—¬ì–‘ë¡œ     47592  ì£¼ë°©ìš©í’ˆ ë° ê°€ì •ìš© ìœ ë¦¬, ìš”ì—…ì œí’ˆ ì†Œë§¤ì—…   \n",
       "2        2024      3  1143        ì—¬ì–‘ë¡œ     47611         ì„œì , ì‹ ë¬¸ ë° ì¡ì§€ë¥˜ ì†Œë§¤ì—…   \n",
       "3        2024      3  1143        ì—¬ì–‘ë¡œ     47631            ìš´ë™ ë° ê²½ê¸°ìš©í’ˆ ì†Œë§¤ì—…   \n",
       "4        2024      3  1143        ì—¬ì–‘ë¡œ     47632        ìì „ê±° ë° ê¸°íƒ€ ìš´ì†¡ì¥ë¹„ ì†Œë§¤ì—…   \n",
       "...       ...    ...   ...        ...       ...                      ...   \n",
       "69189    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47591          ì „ê¸°ìš©í’ˆ ë° ì¡°ëª…ì¥ì¹˜ ì†Œë§¤ì—…   \n",
       "69190    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47520                   ê°€êµ¬ ì†Œë§¤ì—…   \n",
       "69191    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47511            ì² ë¬¼ ë° ë‚œë°©ìš©êµ¬ ì†Œë§¤ì—…   \n",
       "69192    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47422     ì˜ë³µ ì•¡ì„¸ì„œë¦¬ ë° ëª¨ì¡° ì¥ì‹ êµ¬ ì†Œë§¤ì—…   \n",
       "69193    2024      3  1648   ì˜¬ë ˆí”Œë¼ìì‹œí¥ì      47414            ì…”ì¸  ë° ë¸”ë¼ìš°ìŠ¤ ì†Œë§¤ì—…   \n",
       "\n",
       "            AMT   NOC         lon        lat  \\\n",
       "0       2352809    36  127.605348  37.356399   \n",
       "1       6969499     5  127.605348  37.356399   \n",
       "2         45261     1  127.605348  37.356399   \n",
       "3       5416628    20  127.605348  37.356399   \n",
       "4       4762640    90  127.605348  37.356399   \n",
       "...         ...   ...         ...        ...   \n",
       "69189  12616929   202  126.798050  37.444513   \n",
       "69190   2032093     1  126.798050  37.444513   \n",
       "69191  62150740   239  126.798050  37.444513   \n",
       "69192  33922877   522  126.798050  37.444513   \n",
       "69193  40299634  1370  126.798050  37.444513   \n",
       "\n",
       "                                                    meta  \n",
       "0      {'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...  \n",
       "1      {'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...  \n",
       "2      {'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...  \n",
       "3      {'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...  \n",
       "4      {'address_name': 'ê²½ê¸° ì—¬ì£¼ì‹œ ëŒ€ì‹ ë©´ í›„í¬ë¦¬ 500-13', 'cat...  \n",
       "...                                                  ...  \n",
       "69189  {'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...  \n",
       "69190  {'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...  \n",
       "69191  {'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...  \n",
       "69192  {'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...  \n",
       "69193  {'address_name': 'ê²½ê¸° ì‹œí¥ì‹œ ì€í–‰ë™ 535', 'category_g...  \n",
       "\n",
       "[69194 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185f4f4",
   "metadata": {},
   "source": [
    "### ì‹¤íŒ¨í•œ ê²ƒë“¤ ì¬ì‹œë„ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed61fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) ê²½ê¸°ë„ ì‹œ/êµ°/êµ¬ ëª©ë¡ =====\n",
    "GG_CITIES = [\n",
    "    # ì‹œ(ê´‘ì—­ ëŒ€ë„ì‹œ ìš°ì„ )\n",
    "    \"ìˆ˜ì›ì‹œ\", \"ìš©ì¸ì‹œ\", \"ê³ ì–‘ì‹œ\", \"ì„±ë‚¨ì‹œ\", \"ë¶€ì²œì‹œ\", \"ì•ˆì‚°ì‹œ\", \"ì•ˆì–‘ì‹œ\", \"ë‚¨ì–‘ì£¼ì‹œ\",\n",
    "    \"í™”ì„±ì‹œ\", \"í‰íƒì‹œ\", \"ì˜ì •ë¶€ì‹œ\", \"ì‹œí¥ì‹œ\", \"íŒŒì£¼ì‹œ\", \"ê¹€í¬ì‹œ\", \"ê´‘ëª…ì‹œ\", \"ê´‘ì£¼ì‹œ\",\n",
    "    \"êµ°í¬ì‹œ\", \"êµ¬ë¦¬ì‹œ\", \"ì˜¤ì‚°ì‹œ\", \"ì´ì²œì‹œ\", \"í•˜ë‚¨ì‹œ\", \"ì˜ì™•ì‹œ\", \"ì•ˆì„±ì‹œ\", \"ì–‘ì£¼ì‹œ\",\n",
    "    \"ë™ë‘ì²œì‹œ\", \"ê³¼ì²œì‹œ\", \"ì—¬ì£¼ì‹œ\", \"í¬ì²œì‹œ\",\n",
    "    # êµ°\n",
    "    \"ì–‘í‰êµ°\", \"ê°€í‰êµ°\", \"ì—°ì²œêµ°\"\n",
    "]\n",
    "\n",
    "# ì´ë¦„ ì†ì—ì„œ ì´ë¯¸ 'ìˆ˜ì›','ì˜ì •ë¶€' ê°™ì€ ì‹œ/êµ° í‚¤ì›Œë“œê°€ ë³´ì´ë©´ ê·¸ê±¸ ìµœìš°ì„ ìœ¼ë¡œ ì‹œë„\n",
    "def _extract_city_hint_from_name(name: str) -> list[str]:\n",
    "    hits = []\n",
    "    for c in GG_CITIES:\n",
    "        short = c.replace(\"ì‹œ\",\"\").replace(\"êµ°\",\"\")\n",
    "        if short and short in name:\n",
    "            hits.append(c)\n",
    "    return list(dict.fromkeys(hits))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€\n",
    "\n",
    "# 'íŒŒì£¼ê¸ˆì´Œë™ìš°ì²´êµ­' â†’ 'íŒŒì£¼ ê¸ˆì´Œë™ ìš°ì²´êµ­' ê°™ì´ í–‰ì •ë‹¨ìœ„ ë¶„ë¦¬ ê°•í™”\n",
    "def _split_admin_units(s: str) -> str:\n",
    "    t = s\n",
    "    # (ì‹œ/êµ°) + (ë™/ì/ë©´/ë¦¬) + ì‹œì„¤ëª…\n",
    "    t = re.sub(r\"^([ê°€-í£]+ì‹œ)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ìš°ì²´êµ­$\", r\"\\1 \\2 ìš°ì²´êµ­\", t)\n",
    "    t = re.sub(r\"^([ê°€-í£]+ì‹œ)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ìš°í¸ì·¨ê¸‰êµ­$\", r\"\\1 \\2 ìš°í¸ì·¨ê¸‰êµ­\", t)\n",
    "    t = re.sub(r\"^([ê°€-í£]+ì‹œ)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ì •ë¥˜ì¥$\", r\"\\1 \\2 ì •ë¥˜ì¥\", t)\n",
    "    t = re.sub(r\"^([ê°€-í£]+ì‹œ)([ê°€-í£]+(ë™|ì|ë©´|ë¦¬))ë²„ìŠ¤í„°ë¯¸ë„$\", r\"\\1 \\2 ë²„ìŠ¤í„°ë¯¸ë„\", t)\n",
    "    # êµ° ë‹¨ìœ„ë„ ì²˜ë¦¬\n",
    "    t = re.sub(r\"^([ê°€-í£]+êµ°)([ê°€-í£]+(ë©´|ë¦¬))ìš°ì²´êµ­$\", r\"\\1 \\2 ìš°ì²´êµ­\", t)\n",
    "    t = re.sub(r\"^([ê°€-í£]+êµ°)([ê°€-í£]+(ë©´|ë¦¬))ìš°í¸ì·¨ê¸‰êµ­$\", r\"\\1 \\2 ìš°í¸ì·¨ê¸‰êµ­\", t)\n",
    "    return t\n",
    "\n",
    "# ë„ë¡œëª… â€˜ë³´ê´‘ë¡œâ€™ ê°™ì´ ì§§ì€ ì´ë¦„ì€ ì‹œ íŒíŠ¸ë¥¼ ê°•ì œ ë¶€ì—¬í•œ ì¿¼ë¦¬ ìƒì„±\n",
    "def build_city_sweep_queries(raw_name: str) -> list[str]:\n",
    "    name = raw_name.strip()\n",
    "    qs = []\n",
    "\n",
    "    # 0) ì›ë³¸/ì •ê·œí™”(ë„¤ê°€ ì´ë¯¸ ì“°ëŠ” normalize_candidates) ê¸°ë°˜ ë² ì´ìŠ¤ í™•ë³´\n",
    "    base_cands = normalize_candidates(name)\n",
    "    base_cands = [_split_admin_units(x) for x in base_cands]\n",
    "\n",
    "    # 1) ì´ë¦„ ì•ˆì— ì´ë¯¸ ë³´ì´ëŠ” ì‹œ/êµ° íŒíŠ¸ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ\n",
    "    seen_hints = _extract_city_hint_from_name(\" \".join(base_cands))\n",
    "    if seen_hints:\n",
    "        for city in seen_hints:\n",
    "            for b in base_cands:\n",
    "                qs.append(f\"{city} {b}\")\n",
    "\n",
    "    # 2) ìš°ì²´êµ­/ì •ë¥˜ì¥/ë²„ìŠ¤í„°ë¯¸ë„/ì—­ì¶œêµ¬ ì¼€ì´ìŠ¤ëŠ” ë„ì‹œ íŒíŠ¸ê°€ ê²°ì •íƒ€\n",
    "    is_poi = bool(re.search(r\"ìš°ì²´êµ­|ìš°í¸ì·¨ê¸‰êµ­|ì·¨ê¸‰êµ­|ì •ë¥˜ì¥|ë²„ìŠ¤í„°ë¯¸ë„|í„°ë¯¸ë„|ì—­(\\s*\\d+ë²ˆì¶œêµ¬)?$\", name))\n",
    "    is_road = _is_road_like(name) or bool(re.search(r\"\\d+ë²ˆê¸¸$\", name))\n",
    "\n",
    "    # 3) ë„ë¡œëª… ì§§ìŒ(ë³´ê´‘ë¡œ ë“±) ë˜ëŠ” POIë©´ ë„ì‹œ ìŠ¤ìœ• í™•ëŒ€\n",
    "    city_pool = GG_CITIES\n",
    "    if is_road or is_poi or len(_normalize_text(name)) <= 6:\n",
    "        for city in city_pool:\n",
    "            for b in base_cands:\n",
    "                qs.append(f\"{city} {b}\")\n",
    "\n",
    "    # 4) â€˜ê²½ê¸°ë„ {city} {name}â€™ ê°•ì œ ë²„ì „ë„ ì¶”ê°€\n",
    "    for city in city_pool[:12]:  # ìƒìœ„ ë„ì‹œ 12ê°œë§Œ ìš°ì„ (ì†ë„/ì¿¼í„° ë³´í˜¸)\n",
    "        for b in base_cands[:3]: # í›„ë³´ 3ê°œë§Œ\n",
    "            qs.append(f\"ê²½ê¸°ë„ {city} {b}\")\n",
    "\n",
    "    # 5) ì¤‘ë³µ ì œê±° ë° ê³¼ë„í•œ ê¸¸ì´ ì»·\n",
    "    qset, out = set(), []\n",
    "    for q in qs:\n",
    "        q = re.sub(r\"\\s+\", \" \", q).strip()\n",
    "        if 1 < len(q) < 60 and q not in qset:\n",
    "            qset.add(q); out.append(q)\n",
    "    return out[:120]  # ìµœì¢… 120ê°œ ì´ë‚´ë¡œ ì œí•œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43060fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_with_city_sweep(name: str, sleep=0.25):\n",
    "    # 1ì°¨: ê¸°ì¡´ geocode_one (ì´ë¯¸ ì‹¤í–‰í–ˆìœ¼ë¯€ë¡œ ë³´í†µ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë§Œ ì˜´)\n",
    "    lon, lat, payload = geocode_one(name, retry_sleep=sleep)\n",
    "    if lon is not None and lat is not None:\n",
    "        return lon, lat, payload, name\n",
    "\n",
    "    # 2ì°¨: ë„ì‹œ ìŠ¤ìœ• ì¿¼ë¦¬ë“¤ ìˆœì°¨ ì‹œë„\n",
    "    for q in build_city_sweep_queries(name):\n",
    "        lon, lat, payload = geocode_one(q, retry_sleep=sleep)\n",
    "        if lon is not None and lat is not None:\n",
    "            return lon, lat, payload, q\n",
    "    return None, None, None, None\n",
    "\n",
    "\n",
    "def retry_failed_with_city_sweep(failed_csv=\"failed_names.csv\", sleep=0.30):\n",
    "    if not os.path.exists(failed_csv):\n",
    "        print(\"â­ ì‹¤íŒ¨ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\"); \n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "    fnames = pd.read_csv(failed_csv, encoding=\"utf-8-sig\")[\"BIZDIST_NM\"].astype(str).tolist()\n",
    "    fixed_rows, still = [], []\n",
    "\n",
    "    for nm in tqdm(fnames, desc=\"City-sweep retry\", unit=\"name\"):\n",
    "        lon, lat, payload, used_q = geocode_with_city_sweep(nm, sleep=sleep)\n",
    "        if lon is not None and lat is not None:\n",
    "            fixed_rows.append({\n",
    "                \"BIZDIST_NM\": nm,        # ì›ë˜ ì´ë¦„\n",
    "                \"used_query\": used_q,    # ì–´ë–¤ ì¿¼ë¦¬ë¡œ ì„±ê³µí–ˆëŠ”ì§€\n",
    "                \"lon\": lon, \"lat\": lat, \"meta\": payload\n",
    "            })\n",
    "        else:\n",
    "            still.append(nm)\n",
    "\n",
    "    fixed_df = pd.DataFrame(fixed_rows)\n",
    "    if not fixed_df.empty:\n",
    "        fixed_df.to_csv(\"failed_fixed_city.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    if still:\n",
    "        pd.DataFrame({\"BIZDIST_NM\": still}).to_csv(\"failed_still_city.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ™ï¸ ë„ì‹œìŠ¤ìœ• ê²°ê³¼: ê³ ì³ì§ {len(fixed_rows)} / ì—¬ì „íˆ ì‹¤íŒ¨ {len(still)}\")\n",
    "    return fixed_df, still\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "City-sweep retry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [5:52:21<00:00, 183.84s/name] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ ë„ì‹œìŠ¤ìœ• ê²°ê³¼: ê³ ì³ì§ 11 / ì—¬ì „íˆ ì‹¤íŒ¨ 104\n",
      "âœ… ë³´ê°• ë³‘í•© ì™„ë£Œ: ì¢Œí‘œì„±ê³µ 64623 / 69194 (93.4%)\n",
      "ğŸ’¾ ì €ì¥: BIZDIST_with_coords_v2.csv\n"
     ]
    }
   ],
   "source": [
    "fixed_city_df, still = retry_failed_with_city_sweep(\"failed_names.csv\", sleep=0.35)\n",
    "\n",
    "if not fixed_city_df.empty:\n",
    "    # map_df ì—…ë°ì´íŠ¸ (ìˆë‹¤ê³  ê°€ì •)\n",
    "    base = map_df.drop(columns=[\"lon\",\"lat\",\"meta\"], errors=\"ignore\")\n",
    "    patched = base.merge(fixed_city_df[[\"BIZDIST_NM\",\"lon\",\"lat\",\"meta\"]], on=\"BIZDIST_NM\", how=\"left\")\n",
    "    map_df[\"lon\"]  = map_df[\"lon\"].fillna(patched[\"lon\"])\n",
    "    map_df[\"lat\"]  = map_df[\"lat\"].fillna(patched[\"lat\"])\n",
    "    map_df[\"meta\"] = map_df[\"meta\"].where(map_df[\"meta\"].notna(), patched[\"meta\"])\n",
    "\n",
    "    # ì›ë³¸ dfì—ë„ ë°˜ì˜\n",
    "    df = df.drop(columns=[\"lon\",\"lat\",\"meta\"], errors=\"ignore\").merge(map_df, on=\"BIZDIST_NM\", how=\"left\")\n",
    "\n",
    "    print(f\"âœ… ë³´ê°• ë³‘í•© ì™„ë£Œ: ì¢Œí‘œì„±ê³µ {df['lon'].notna().sum()} / {len(df)} ({df['lon'].notna().mean():.1%})\")\n",
    "    df.to_csv(\"ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ_ìœ„ê²½ë„(2).csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"ğŸ’¾ ì €ì¥: ê²½ê¸°ë„ê³¨ëª©ìƒê¶Œë§¤ì¶œ_ìœ„ê²½ë„(2).csv\")\n",
    "else:\n",
    "    print(\"â—ë³´ê°• ì„±ê³µ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. failed_still_city.csv í™•ì¸ í›„ ALIAS/ì •ê·œí™” ê·œì¹™ ì¶”ê°€ ê¶Œì¥.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2c4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
