{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb4ea21-f390-4618-bb0e-6ef9e3d2c3ef",
   "metadata": {},
   "source": [
    "ìƒê¶Œìˆ˜ì§‘ì„ 'ë¡œ' ê¸°ì¤€ìœ¼ë¡œ í•˜ë‹ˆ ë„ˆë¬´ ì ì–´ì„œ ë‹¨ì†ì§€ì  ê¸°ì¤‘ ì£¼ë³€ ìƒê¶Œìœ¼ë¡œ ì„¤ì •í•˜ë ¤ë‹¤ê°€\n",
    "ì•ˆë¼ì„œ ê·¸ëƒ¥ ìˆ˜ì›ì‹œë¥¼ 300mê°„ê²©ì˜ gridë¡œ ë‚˜ëˆ„ê³  ê·¸ 300më‘˜ë ˆì˜ ìƒê¶Œì˜ ê°œìˆ˜ë¥¼ ì…ˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6676df4-b02b-4324-be07-b9f88417a2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 42ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±ë¨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í´ëŸ¬ìŠ¤í„° ìƒê¶Œ ì¡°íšŒì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:37<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ ì €ì¥ ì™„ë£Œ: ì£¼ì •ì°¨ìœ„ë°˜ê¸°ì¤€ìƒê¶Œ.csv\n",
      "   cluster_id        lat         lng  ë‹¨ì†ê±´ìˆ˜í•©ê³„  ìŒì‹ì   ì¹´í˜  ì€í–‰  ë³‘ì›  ê´€ê³µì„œ  ì£¼ì°¨ì¥  ì´í•©\n",
      "0           0  37.272840  127.019846  302922   23  10   7  12    0    4  56\n",
      "1           1  37.269641  126.952887   19726   45   7   2   1    0    1  56\n",
      "2           2  37.233443  126.976255     376    6   5   1   2    0    0  14\n",
      "3           3  37.322786  126.991538      84    1   0   0   0    0    0   1\n",
      "4           4  37.266418  126.983914     259    5   1   0   0    0    1   7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "violations.json ë‹¨ì†ì§€ì  ì¢Œí‘œë¥¼ 300m ë°˜ê²½ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ í›„\n",
    "í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ì¢Œí‘œ ê¸°ì¤€ ìƒê¶Œ ê°œìˆ˜ ì§‘ê³„\n",
    "ì¶œë ¥: ì£¼ì •ì°¨ìœ„ë°˜ê¸°ì¤€ìƒê¶Œ.csv\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# ================= ì„¤ì • =================\n",
    "API_KEY = os.getenv(\"KAKAO_API_KEY\", \"41d56449d3dce5dde7d48ffb261f0e8a\")\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"FD6\": \"ìŒì‹ì \",\n",
    "    \"CE7\": \"ì¹´í˜\",\n",
    "    \"BK9\": \"ì€í–‰\",\n",
    "    \"HP8\": \"ë³‘ì›\",\n",
    "    \"PO3\": \"ê´€ê³µì„œ\",\n",
    "    \"PK6\": \"ì£¼ì°¨ì¥\",\n",
    "}\n",
    "\n",
    "RADIUS_M = 300   # ë°˜ê²½(m)\n",
    "SLEEP_SEC = 0.08\n",
    "HEADERS = {\"Authorization\": f\"KakaoAK {API_KEY}\"}\n",
    "\n",
    "# ================= ìœ í‹¸ í•¨ìˆ˜ =================\n",
    "def _request_json(url: str, params: dict, retry: int = 3, backoff: float = 0.6) -> dict:\n",
    "    last_err = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            res = requests.get(url, headers=HEADERS, params=params, timeout=6)\n",
    "            if res.status_code == 200:\n",
    "                return res.json()\n",
    "            last_err = f\"status={res.status_code}, body={res.text[:200]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "        time.sleep(backoff * (2 ** i))\n",
    "    raise RuntimeError(f\"GET ì‹¤íŒ¨: {url} params={params} err={last_err}\")\n",
    "\n",
    "def count_nearby(lat: float, lng: float, category_group_code: str, radius_m: int = 300) -> int:\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/category.json\"\n",
    "    params = {\n",
    "        \"category_group_code\": category_group_code,\n",
    "        \"x\": lng, \"y\": lat,\n",
    "        \"radius\": radius_m,\n",
    "        \"size\": 1, \"page\": 1,\n",
    "    }\n",
    "    try:\n",
    "        data = _request_json(url, params)\n",
    "        meta = data.get(\"meta\", {})\n",
    "        return int(meta.get(\"total_count\", 0))\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: code={category_group_code} ({lat},{lng}) -> {e}\")\n",
    "        return 0\n",
    "\n",
    "# ================= ë©”ì¸ ë¡œì§ =================\n",
    "def cluster_and_enrich(violations_path=\"violations.json\", out_csv=\"ì£¼ì •ì°¨ìœ„ë°˜ê¸°ì¤€ìƒê¶Œ.csv\"):\n",
    "    with open(violations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        violations = json.load(f)\n",
    "\n",
    "    # ì¢Œí‘œ ë°°ì—´ (lat, lon)\n",
    "    coords = np.array([[v[\"lat\"], v[\"lon\"]] for v in violations])\n",
    "\n",
    "    # DBSCAN: epsâ‰ˆ0.003ë„ (ì•½ 300m), min_samples=1\n",
    "    clustering = DBSCAN(eps=0.003, min_samples=1, metric=\"euclidean\").fit(coords)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    # DataFrame ìƒì„±\n",
    "    df = pd.DataFrame(violations)\n",
    "    df[\"cluster\"] = labels\n",
    "\n",
    "    # í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì¢Œí‘œ + ë‹¨ì†ê±´ìˆ˜ í•©ê³„\n",
    "    clusters = df.groupby(\"cluster\").agg({\n",
    "        \"lat\": \"mean\",\n",
    "        \"lon\": \"mean\",\n",
    "        \"count\": \"sum\"\n",
    "    }).reset_index().rename(columns={\"lon\": \"lng\", \"count\": \"ë‹¨ì†ê±´ìˆ˜í•©ê³„\"})\n",
    "\n",
    "    print(f\"âœ… ì´ {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±ë¨\")\n",
    "\n",
    "    rows = []\n",
    "    # âœ… tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ\n",
    "    for _, r in tqdm(clusters.iterrows(), total=len(clusters), desc=\"í´ëŸ¬ìŠ¤í„° ìƒê¶Œ ì¡°íšŒì¤‘\"):\n",
    "        row = {\n",
    "            \"cluster_id\": int(r[\"cluster\"]),\n",
    "            \"lat\": r[\"lat\"],\n",
    "            \"lng\": r[\"lng\"],\n",
    "            \"ë‹¨ì†ê±´ìˆ˜í•©ê³„\": int(r[\"ë‹¨ì†ê±´ìˆ˜í•©ê³„\"]),\n",
    "        }\n",
    "        total = 0\n",
    "        for code, name in CATEGORIES.items():\n",
    "            cnt = count_nearby(row[\"lat\"], row[\"lng\"], code, RADIUS_M)\n",
    "            row[name] = cnt\n",
    "            total += cnt\n",
    "            time.sleep(SLEEP_SEC)\n",
    "        row[\"ì´í•©\"] = total\n",
    "        rows.append(row)\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    df_out.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"\\nğŸ“¦ ì €ì¥ ì™„ë£Œ: {out_csv}\")\n",
    "    print(df_out.head())\n",
    "    return df_out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cluster_and_enrich()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0694e5-6422-4a42-b40f-75d51b9d7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… facilities.json ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) íŒŒì¼ ì´ë¦„ ì§€ì •\n",
    "counts_csv = \"ì£¼ì •ì°¨ìœ„ë°˜ê¸°ì¤€ìƒê¶Œ.csv\"\n",
    "counts_json = \"facilities.json\"\n",
    "\n",
    "# 2) CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_counts = pd.read_csv(counts_csv)\n",
    "\n",
    "# 3) JSONìœ¼ë¡œ ì €ì¥ (UTF-8, ë³´ê¸° ì¢‹ê²Œ ë“¤ì—¬ì“°ê¸°)\n",
    "df_counts.to_json(counts_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… {counts_json} ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e80aeb7-e894-48d3-a8ac-f2926af122ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.1.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting pyproj\n",
      "  Downloading pyproj-3.7.2-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\somin\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\somin\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\somin\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from shapely) (1.26.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\somin\\anaconda3\\lib\\site-packages (from pyproj) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\somin\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\somin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading shapely-2.1.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.4/1.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.5 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.7.2-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.6/6.3 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.5/6.3 MB 20.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.0/6.3 MB 19.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.3 MB 19.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.3 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 16.8 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, pyproj\n",
      "Successfully installed pyproj-3.7.2 shapely-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shapely pyproj tqdm requests pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aeafc4-e822-4150-86dd-59e3a313c969",
   "metadata": {},
   "source": [
    "ì´ê±°ë¡œ facilitiesì €ì¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fc777d-0206-4d36-be10-e7175e6d6af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ë¦¬ë“œ ì  ê°œìˆ˜: 3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì¹´í…Œê³ ë¦¬ ì§‘ê³„: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3360/3360 [51:58<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì €ì¥ ì™„ë£Œ: grid_poi_suwon.csv\n",
      "    lat         lng  ìŒì‹ì   ì¹´í˜  ì€í–‰  ë³‘ì›  ê´€ê³µì„œ  ì£¼ì°¨ì¥  ì´í•©\n",
      "0  37.2  126.900000    3   0   0   0    0    0   3\n",
      "1  37.2  126.903387    0   0   0   0    0    0   0\n",
      "2  37.2  126.906773    0   0   0   0    0    0   0\n",
      "3  37.2  126.910160    1   1   0   0    0    0   2\n",
      "4  37.2  126.913547    1   1   0   0    0    0   2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ìˆ˜ì›ì‹œ bbox ì˜ì—­ì„ ì¼ì • ê°„ê²©(Grid)ìœ¼ë¡œ ìƒ˜í”Œë§í•˜ì—¬\n",
    "ê° ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ë°˜ê²½ ë‚´ ì¹´ì¹´ì˜¤ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ë¥¼ ì§‘ê³„\n",
    "ì¶œë ¥: grid_poi_suwon.csv\n",
    "\"\"\"\n",
    "import os, math, time, json, requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== ì„¤ì • =====\n",
    "API_KEY = os.getenv(\"KAKAO_API_KEY\", \"41d56449d3dce5dde7d48ffb261f0e8a\")\n",
    "HEADERS = {\"Authorization\": f\"KakaoAK {API_KEY}\"}\n",
    "\n",
    "# ìˆ˜ì›ì‹œ ëŒ€ëµ bbox (ë‚¨,ì„œ,ë¶,ë™)\n",
    "SUWON_BBOX = (37.20, 126.90, 37.35, 127.10)\n",
    "\n",
    "GRID_STEP_M = 300     # ê²©ì ê°„ê²© (m) â€” 200~600 ì‚¬ì´ì—ì„œ ì¡°ì ˆ\n",
    "RADIUS_M    = 300     # ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ë°˜ê²½ (m)\n",
    "SLEEP_SEC   = 0.08    # rate limit ì™„í™”\n",
    "VERIFY_CITY = False   # Trueë©´ ì—­ì§€ì˜¤ì½”ë”©ìœ¼ë¡œ 'ìˆ˜ì›ì‹œ'ë§Œ ë‚¨ê¹€(í˜¸ì¶œëŸ‰ ì¦ê°€)\n",
    "CACHE_PATH  = \"kakao_count_cache.json\"\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"FD6\":\"ìŒì‹ì \",\n",
    "    \"CE7\":\"ì¹´í˜\",\n",
    "    \"BK9\":\"ì€í–‰\",\n",
    "    \"HP8\":\"ë³‘ì›\",\n",
    "    \"PO3\":\"ê´€ê³µì„œ\",\n",
    "    \"PK6\":\"ì£¼ì°¨ì¥\",\n",
    "}\n",
    "\n",
    "# ===== ìœ í‹¸ =====\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_PATH):\n",
    "        try:\n",
    "            return json.load(open(CACHE_PATH, \"r\", encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    tmp = CACHE_PATH + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, ensure_ascii=False)\n",
    "    os.replace(tmp, CACHE_PATH)\n",
    "\n",
    "def cache_key(lat,lng,code,r):\n",
    "    return f\"{round(lat,6)}|{round(lng,6)}|{code}|{r}\"\n",
    "\n",
    "def _get(url, params, retry=3, backoff=0.6):\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params, timeout=8)\n",
    "            if r.status_code == 200:\n",
    "                return r.json()\n",
    "            last = f\"status={r.status_code} body={r.text[:120]}\"\n",
    "        except Exception as e:\n",
    "            last = str(e)\n",
    "        time.sleep(backoff*(2**i))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "def kakao_total_count(lat,lng,code,rad,cache):\n",
    "    k = cache_key(lat,lng,code,rad)\n",
    "    if k in cache:\n",
    "        return cache[k]\n",
    "    data = _get(\"https://dapi.kakao.com/v2/local/search/category.json\",\n",
    "                {\"category_group_code\":code,\"x\":lng,\"y\":lat,\"radius\":rad,\"size\":1,\"page\":1})\n",
    "    total = int(data.get(\"meta\",{}).get(\"total_count\",0))\n",
    "    cache[k] = total\n",
    "    return total\n",
    "\n",
    "def kakao_region(lat,lng):\n",
    "    data = _get(\"https://dapi.kakao.com/v2/local/geo/coord2address.json\", {\"x\":lng,\"y\":lat})\n",
    "    docs = data.get(\"documents\",[])\n",
    "    if not docs: return None\n",
    "    return docs[0].get(\"road_address\") or docs[0].get(\"address\")\n",
    "\n",
    "def meters_to_deg(lat, meters):\n",
    "    # ìœ„ë„ 1ë„ â‰ˆ 111,320 m\n",
    "    dlat = meters / 111320.0\n",
    "    # ê²½ë„ 1ë„ â‰ˆ 111,320 * cos(lat)\n",
    "    dlon = meters / (111320.0 * math.cos(math.radians(lat)))\n",
    "    return dlat, dlon\n",
    "\n",
    "def grid_points(bbox, step_m):\n",
    "    S,W,N,E = bbox\n",
    "    mid_lat = (S+N)/2\n",
    "    dlat, dlon = meters_to_deg(mid_lat, step_m)\n",
    "    pts = []\n",
    "    lat = S\n",
    "    while lat <= N:\n",
    "        lon = W\n",
    "        while lon <= E:\n",
    "            pts.append((round(lat,6), round(lon,6)))\n",
    "            lon += dlon\n",
    "        lat += dlat\n",
    "    return pts\n",
    "\n",
    "# ===== ë©”ì¸ =====\n",
    "def build_grid(out_csv=\"grid_poi_suwon.csv\"):\n",
    "    cache = load_cache()\n",
    "    pts = grid_points(SUWON_BBOX, GRID_STEP_M)\n",
    "    print(f\"ê·¸ë¦¬ë“œ ì  ê°œìˆ˜: {len(pts)}\")\n",
    "\n",
    "    rows = []\n",
    "    for (lat,lng) in tqdm(pts, desc=\"ì¹´í…Œê³ ë¦¬ ì§‘ê³„\"):\n",
    "        if VERIFY_CITY:\n",
    "            info = kakao_region(lat,lng)\n",
    "            if not info: \n",
    "                time.sleep(SLEEP_SEC); \n",
    "                continue\n",
    "            # road_address ë˜ëŠ” addressì˜ 2depthê°€ 'ìˆ˜ì›ì‹œ'ì¸ì§€ í™•ì¸\n",
    "            if not (info.get(\"region_2depth_name\") == \"ìˆ˜ì›ì‹œ\" or info.get(\"region_2depth_name\") == \"ìˆ˜ì›íŠ¹ë¡€ì‹œ\"):\n",
    "                time.sleep(SLEEP_SEC); \n",
    "                continue\n",
    "\n",
    "        row = {\"lat\":lat, \"lng\":lng}\n",
    "        total = 0\n",
    "        for code,label in CATEGORIES.items():\n",
    "            cnt = kakao_total_count(lat,lng,code,RADIUS_M,cache)\n",
    "            row[label] = cnt\n",
    "            total += cnt\n",
    "            time.sleep(SLEEP_SEC)\n",
    "        row[\"ì´í•©\"] = total\n",
    "        rows.append(row)\n",
    "\n",
    "    save_cache(cache)\n",
    "\n",
    "    if not rows:\n",
    "        print(\"âš ï¸ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“¦ ì €ì¥ ì™„ë£Œ: {out_csv}\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce78315c-245c-44a6-9d23-0f18fe23bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… facilities.json ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) íŒŒì¼ ì´ë¦„ ì§€ì •\n",
    "counts_csv = \"grid_poi_suwon.csv\"\n",
    "counts_json = \"facilities.json\"\n",
    "\n",
    "# 2) CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_counts = pd.read_csv(counts_csv)\n",
    "\n",
    "# 3) JSONìœ¼ë¡œ ì €ì¥ (UTF-8, ë³´ê¸° ì¢‹ê²Œ ë“¤ì—¬ì“°ê¸°)\n",
    "df_counts.to_json(counts_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… {counts_json} ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39db380-6bd0-45bc-8c4d-2404047b71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì†Ÿê°’:\n",
      "lat     37.2\n",
      "lng    126.9\n",
      "ìŒì‹ì       0.0\n",
      "ì¹´í˜       0.0\n",
      "ì€í–‰       0.0\n",
      "ë³‘ì›       0.0\n",
      "ê´€ê³µì„œ      0.0\n",
      "ì£¼ì°¨ì¥      0.0\n",
      "ì´í•©       0.0\n",
      "dtype: float64\n",
      "\n",
      "ìµœëŒ“ê°’:\n",
      "lat     37.348221\n",
      "lng    127.099816\n",
      "ìŒì‹ì     462.000000\n",
      "ì¹´í˜     118.000000\n",
      "ì€í–‰      28.000000\n",
      "ë³‘ì›      98.000000\n",
      "ê´€ê³µì„œ      6.000000\n",
      "ì£¼ì°¨ì¥     45.000000\n",
      "ì´í•©     716.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"grid_poi_suwon.csv\")\n",
    "\n",
    "# ê° ì—´ì˜ ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ ê³„ì‚°\n",
    "min_values = df.min()\n",
    "max_values = df.max()\n",
    "\n",
    "print(\"ìµœì†Ÿê°’:\")\n",
    "print(min_values)\n",
    "print(\"\\nìµœëŒ“ê°’:\")\n",
    "print(max_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f59a7-7cc7-4ab6-9ee9-86d0c0e12a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
