{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd961e5-deb5-4a56-aca0-6548a846a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì¢Œí‘œ ìºì‹œ ì €ì¥: road_coords.csv (rows=10)\n",
      "\n",
      "ğŸ“¦ ì €ì¥ ì™„ë£Œ\n",
      "  - road_coords.csv\n",
      "  - road_category_counts_radius500_m.csv\n",
      "\n",
      "â–¶ ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°:\n",
      "   road        lat         lng  ìŒì‹ì    ì¹´í˜  ì€í–‰   ë³‘ì›  ê´€ê³µì„œ  ì£¼ì°¨ì¥  ìŒì‹+ì¹´í˜    ì´í•©\n",
      "0   íš¨ì›ë¡œ  37.262885  127.030425  714  149  56  129    2   71    863  1121\n",
      "1   ê¶Œê´‘ë¡œ  37.263906  127.032310  670  142  57  126    2   70    812  1067\n",
      "2  ìˆ˜ì›ì²œë¡œ  37.287506  127.018074  227  128   8    5    1   17    355   386\n",
      "3   ê¸ˆê³¡ë¡œ  37.274591  126.956151  252   51  11   36    3   19    303   372\n",
      "4   ì˜í†µë¡œ  37.238421  127.057025  191   39  13   45    4   11    230   303\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ë„ë¡œ ì¤‘ì‹¬ ìœ„ê²½ë„ + ë°˜ê²½ ë‚´ ì¹´í…Œê³ ë¦¬ 'ê°œìˆ˜ë§Œ' ì§‘ê³„í•˜ì—¬ CSV ì €ì¥\n",
    "- road_coords.csv : ë„ë¡œëª…, ìœ„ë„, ê²½ë„ (ì¢Œí‘œ ìºì‹œ)\n",
    "- road_category_counts_radius{r}_m.csv : ë„ë¡œë³„ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ ìš”ì•½\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# ================= ì„¤ì • =================\n",
    "API_KEY = os.getenv(\"KAKAO_API_KEY\", \"41d56449d3dce5dde7d48ffb261f0e8a\")\n",
    "CITY_PREFIX = \"ìˆ˜ì›ì‹œ\"\n",
    "TARGET_ROADS = [\"íŒ”ë‹¬ë¡œ\", \"ê¶Œì„ ë¡œ\", \"ê²½ìˆ˜ëŒ€ë¡œ\", \"íš¨ì›ë¡œ\", \"ìˆ˜ì›ì²œë¡œ\", \"ì¥ë‹¤ë¦¬ë¡œ\", \"ê¶Œê´‘ë¡œ\", \"ê¸ˆê³¡ë¡œ\", \"ì •ì¡°ë¡œ\", \"ì˜í†µë¡œ\"]\n",
    "\n",
    "# ìˆ˜ì§‘ ì¹´í…Œê³ ë¦¬ (ìš”êµ¬ì‚¬í•­ ê³ ì •)\n",
    "CATEGORIES = {\n",
    "    \"FD6\": \"ìŒì‹ì \",\n",
    "    \"CE7\": \"ì¹´í˜\",\n",
    "    \"BK9\": \"ì€í–‰\",\n",
    "    \"HP8\": \"ë³‘ì›\",\n",
    "    \"PO3\": \"ê´€ê³µì„œ\",\n",
    "    \"PK6\": \"ì£¼ì°¨ì¥\",\n",
    "}\n",
    "\n",
    "# ê²€ìƒ‰ ë°˜ê²½ (ë¯¸í„°)\n",
    "RADIUS_M = 500\n",
    "\n",
    "# ìˆ˜ì› ì¤‘ì‹¬(ë°”ì´ì–´ìŠ¤ìš©)\n",
    "CENTER_X = \"127.0286\"\n",
    "CENTER_Y = \"37.2636\"\n",
    "\n",
    "# API ìš”ì²­ ê°„ê²©(ì´ˆ)\n",
    "SLEEP_SEC = 0.08\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"KakaoAK {API_KEY}\"}\n",
    "\n",
    "# ================= ìœ í‹¸ í•¨ìˆ˜ =================\n",
    "def _request_json(url: str, params: dict, retry: int = 3, backoff: float = 0.6) -> dict:\n",
    "    \"\"\"ê°„ë‹¨ ì¬ì‹œë„ ì§€ì› GET JSON\"\"\"\n",
    "    last_err = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            res = requests.get(url, headers=HEADERS, params=params, timeout=6)\n",
    "            if res.status_code == 200:\n",
    "                return res.json()\n",
    "            last_err = f\"status={res.status_code}, body={res.text[:200]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "        time.sleep(backoff * (2 ** i))\n",
    "    raise RuntimeError(f\"GET ì‹¤íŒ¨: {url} params={params} err={last_err}\")\n",
    "\n",
    "def get_road_coord(road_name: str) -> Optional[Dict]:\n",
    "    \"\"\"ë„ë¡œ ì¤‘ì‹¬ ì¢Œí‘œ 1ê±´ë§Œ ì¡°íšŒ (í‚¤ì›Œë“œ ê²€ìƒ‰)\"\"\"\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/keyword.json\"\n",
    "    params = {\n",
    "        \"query\": f\"{CITY_PREFIX} {road_name}\",\n",
    "        \"x\": CENTER_X, \"y\": CENTER_Y, \"radius\": 20000,\n",
    "        \"size\": 1, \"page\": 1,\n",
    "    }\n",
    "    try:\n",
    "        data = _request_json(url, params)\n",
    "        docs = data.get(\"documents\", [])\n",
    "        if docs:\n",
    "            d = docs[0]\n",
    "            return {\n",
    "                \"road\": road_name,\n",
    "                \"lat\": float(d[\"y\"]),\n",
    "                \"lng\": float(d[\"x\"]),\n",
    "                \"query_addr\": d.get(\"address_name\", \"\"),\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¢Œí‘œ ì‹¤íŒ¨: {road_name} -> {e}\")\n",
    "    return None\n",
    "\n",
    "def count_nearby(lat: float, lng: float, category_group_code: str, radius_m: int = 500) -> int:\n",
    "    \"\"\"ì¹´í…Œê³ ë¦¬ API meta.total_countë§Œ ì‚¬ìš©í•´ì„œ ê°œìˆ˜ ì§‘ê³„\"\"\"\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/category.json\"\n",
    "    params = {\n",
    "        \"category_group_code\": category_group_code,\n",
    "        \"x\": lng, \"y\": lat,\n",
    "        \"radius\": radius_m,\n",
    "        \"size\": 1, \"page\": 1,  # ëª©ë¡ ë¶ˆí•„ìš”, meta.total_countë§Œ í™•ì¸\n",
    "    }\n",
    "    try:\n",
    "        data = _request_json(url, params)\n",
    "        meta = data.get(\"meta\", {})\n",
    "        # ì¹´ì¹´ì˜¤ê°€ total_countë¥¼ 45í˜ì´ì§€*15 = 675ë¡œ ìº¡í•  ìˆ˜ ìˆìŒ(ê²€ìƒ‰ í•œê³„)\n",
    "        # í•˜ì§€ë§Œ ë°˜ê²½ 500m ë‚´ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¶©ë¶„. í•„ìš”ì‹œ ë°˜ê²½ ì¤„ì´ê±°ë‚˜ ê·¸ë¦¬ë“œ ìƒ˜í”Œë§.\n",
    "        return int(meta.get(\"total_count\", 0))\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: code={category_group_code} ({lat},{lng}) -> {e}\")\n",
    "        return 0\n",
    "\n",
    "# ================= ë©”ì¸ ë¡œì§ =================\n",
    "def load_cached_coords(path=\"road_coords.csv\") -> Dict[str, Dict]:\n",
    "    \"\"\"ì´ë¯¸ ì €ì¥ëœ ì¢Œí‘œ ìºì‹œ ì½ê¸° (ìˆìœ¼ë©´ ì¬ì‚¬ìš©)\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return {}\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        out = {}\n",
    "        for _, r in df.iterrows():\n",
    "            out[str(r[\"road\"])] = {\n",
    "                \"road\": r[\"road\"],\n",
    "                \"lat\": float(r[\"lat\"]),\n",
    "                \"lng\": float(r[\"lng\"]),\n",
    "                \"query_addr\": r.get(\"query_addr\", \"\"),\n",
    "            }\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def save_coords_cache(coords: List[Dict], path=\"road_coords.csv\"):\n",
    "    df = pd.DataFrame(coords)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ’¾ ì¢Œí‘œ ìºì‹œ ì €ì¥: {path} (rows={len(df)})\")\n",
    "\n",
    "def collect_counts(radius_m: int = RADIUS_M):\n",
    "    # 1) ì¢Œí‘œ ìºì‹œ í™œìš© + ë¶€ì¡±ë¶„ ì¡°íšŒ\n",
    "    cache = load_cached_coords()\n",
    "    coords: List[Dict] = []\n",
    "    for road in TARGET_ROADS:\n",
    "        if road in cache:\n",
    "            coords.append(cache[road])\n",
    "        else:\n",
    "            c = get_road_coord(road)\n",
    "            if c:\n",
    "                coords.append(c)\n",
    "            else:\n",
    "                print(f\"âš ï¸ ì¢Œí‘œ ì—†ìŒ: {road}\")\n",
    "            time.sleep(SLEEP_SEC)\n",
    "    # ìºì‹œ ê°±ì‹ \n",
    "    save_coords_cache(coords)\n",
    "\n",
    "    # 2) ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ì§‘ê³„(ì—…ì²´ëª… X)\n",
    "    rows = []\n",
    "    for rc in coords:\n",
    "        row = {\"road\": rc[\"road\"], \"lat\": rc[\"lat\"], \"lng\": rc[\"lng\"]}\n",
    "        for code, name in CATEGORIES.items():\n",
    "            cnt = count_nearby(rc[\"lat\"], rc[\"lng\"], code, radius_m)\n",
    "            row[name] = cnt\n",
    "            time.sleep(SLEEP_SEC)\n",
    "        row[\"ìŒì‹+ì¹´í˜\"] = row[\"ìŒì‹ì \"] + row[\"ì¹´í˜\"]\n",
    "        row[\"ì´í•©\"] = sum(row[name] for name in CATEGORIES.values())\n",
    "        rows.append(row)\n",
    "\n",
    "    df_counts = pd.DataFrame(rows).sort_values(\"ì´í•©\", ascending=False).reset_index(drop=True)\n",
    "    out_path = f\"road_category_counts_radius{radius_m}_m.csv\"\n",
    "    df_counts.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\"\\nğŸ“¦ ì €ì¥ ì™„ë£Œ\")\n",
    "    print(f\"  - road_coords.csv\")\n",
    "    print(f\"  - {out_path}\")\n",
    "    print(\"\\nâ–¶ ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(df_counts.head())\n",
    "\n",
    "    return df_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not API_KEY or API_KEY.startswith(\"ì—¬ê¸°ì—_\"):\n",
    "        raise SystemExit(\"â— KAKAO_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”. (í™˜ê²½ë³€ìˆ˜ KAKAO_API_KEY ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ API_KEY)\")\n",
    "    _ = collect_counts(RADIUS_M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8132b2b5-e8d8-4408-bd76-399a391056f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… road_coords.json ì €ì¥ ì™„ë£Œ\n",
      "âœ… road_category_counts_radius500_m.json ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) ë„ë¡œ ì¢Œí‘œ JSON ë³€í™˜\n",
    "coords_csv = \"road_coords.csv\"\n",
    "coords_json = \"road_coords.json\"\n",
    "\n",
    "df_coords = pd.read_csv(coords_csv)\n",
    "df_coords.to_json(coords_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "print(f\"âœ… {coords_json} ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "# 2) ë„ë¡œë³„ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ JSON ë³€í™˜\n",
    "counts_csv = \"road_category_counts_radius500_m.csv\"\n",
    "counts_json = \"road_category_counts_radius500_m.json\"\n",
    "\n",
    "df_counts = pd.read_csv(counts_csv)\n",
    "df_counts.to_json(counts_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "print(f\"âœ… {counts_json} ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d97744-cdd5-4bc5-9a71-09b8dc279a12",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ê°€ .CSVê°€ ì•„ë‹ˆë¼ .JSONí˜•íƒœì—¬ì•¼ í•´ì„œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f45398-03a6-41c6-85c1-0698450649fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ ì œê±°: 44329ê±´ ì œê±°, ë‚¨ì€ 325407ê±´\n",
      "âœ… ì €ì¥ ì™„ë£Œ: data\\violations.json (rows=46797)\n",
      "\n",
      "ë‹¨ì†ë°©ë²• ë¶„í¬(ìƒìœ„ 10):\n",
      " type      n\n",
      "  ê³ ì •í˜• 119853\n",
      "  ì£¼í–‰í˜• 102803\n",
      "êµ­ë¯¼ì‹ ë¬¸ê³   91344\n",
      "   ë³´í–‰   9291\n",
      "ì£¼ë¯¼ì‹ ê³ ì œ   2116\n",
      "\n",
      "ì‹œê°„ëŒ€ ë¶„í¬(0~23):\n",
      "hour\n",
      "0      1846\n",
      "1      1058\n",
      "2       783\n",
      "3       526\n",
      "4       563\n",
      "5      1672\n",
      "6      2257\n",
      "7      8773\n",
      "8     20828\n",
      "9     25836\n",
      "10    34583\n",
      "11    10428\n",
      "12     7849\n",
      "13     8770\n",
      "14    46115\n",
      "15    33535\n",
      "16    22955\n",
      "17    19617\n",
      "18    14936\n",
      "19    24864\n",
      "20    19255\n",
      "21     9475\n",
      "22     5312\n",
      "23     3571\n"
     ]
    }
   ],
   "source": [
    "#ë‹¨ì†ë°ì´í„° ê²°ì¸¡ì¹˜ ì œê±°í•˜ê³  jsoníŒŒì¼ë¡œ ì €ì¥\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ì£¼ì •ì°¨ ë‹¨ì† ë°ì´í„° ì •ë¦¬ â†’ JSON (ì¹´ì¹´ì˜¤ë§µ ë Œë”ìš©)\n",
    "- ì…ë ¥: CSV (í•„ë“œ: ì§‘ê³„ë…„ë„, ì‹œêµ°ëª…, ê´€ë¦¬ê¸°ê´€ëª…, ë‹¨ì†ì¼ì‹œì •ë³´, ë‹¨ì†ë°©ë²•, ë°ì´í„°ê¸°ì¤€ì¼ì, ë‹¨ì†ì¥ì†Œ, lat, lon)\n",
    "- ì¶œë ¥: data/violations.json  (records: [{lat, lon, type, hour, count}, ...])\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===== ê²½ë¡œ/íŒŒì¼ëª… =====\n",
    "INPUT_CSV = \"ì£¼ì •ì°¨ìœ„ë°˜ë‹¨ì†_ìœ„ê²½ë„.csv\" \n",
    "OUTPUT_JSON = os.path.join(\"data\", \"violations.json\")\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# ===== 1) ë¡œë“œ + í•„ìš”í•œ ì»¬ëŸ¼ë§Œ =====\n",
    "# ì¸ì½”ë”© ìë™ ì‹œë„\n",
    "for enc in (\"utf-8\", \"cp949\", \"euc-kr\"):\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV, encoding=enc)\n",
    "        break\n",
    "    except Exception:\n",
    "        df = None\n",
    "if df is None:\n",
    "    raise RuntimeError(\"CSV íŒŒì¼ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¸ì½”ë”©/ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "need_cols = ['ì§‘ê³„ë…„ë„','ì‹œêµ°ëª…','ê´€ë¦¬ê¸°ê´€ëª…','ë‹¨ì†ì¼ì‹œì •ë³´','ë‹¨ì†ë°©ë²•','ë‹¨ì†ì¥ì†Œ','lat','lon']\n",
    "missing = [c for c in need_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}\")\n",
    "\n",
    "df = df[need_cols].copy()\n",
    "\n",
    "# ===== 2) ê¸°ë³¸ ì „ì²˜ë¦¬ =====\n",
    "# ë‚ ì§œ â†’ datetime\n",
    "df['ë‹¨ì†ì¼ì‹œì •ë³´'] = pd.to_datetime(df['ë‹¨ì†ì¼ì‹œì •ë³´'], errors='coerce')\n",
    "\n",
    "# lat/lon ìˆ«ìí™”\n",
    "df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
    "\n",
    "# ê²°ì¸¡ ì œê±°: (ì‹œê°„, ë‹¨ì†ë°©ë²•, lat, lon) ëª¨ë‘ ìˆì–´ì•¼ í•¨\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['ë‹¨ì†ì¼ì‹œì •ë³´', 'ë‹¨ì†ë°©ë²•', 'lat', 'lon'])\n",
    "after = len(df)\n",
    "print(f\"ê²°ì¸¡ ì œê±°: {before - after}ê±´ ì œê±°, ë‚¨ì€ {after}ê±´\")\n",
    "\n",
    "# (ì„ íƒ) ìˆ˜ì› ê·¼ì²˜ ì¢Œí‘œë§Œ ìœ ì§€ (ì´ìƒì¹˜ ì œê±°ìš©: ëŒ€ëµ bounding box)\n",
    "# ìˆ˜ì› ëŒ€ëµ: lat 37.18~37.36, lon 126.92~127.12\n",
    "df = df[(df['lat'].between(37.18, 37.36)) & (df['lon'].between(126.92, 127.12))]\n",
    "\n",
    "# ===== 3) íŒŒìƒ ì»¬ëŸ¼: hour, type =====\n",
    "df['hour'] = df['ë‹¨ì†ì¼ì‹œì •ë³´'].dt.hour.astype(int)\n",
    "\n",
    "# ë‹¨ì†ë°©ë²• ì •ê·œí™”(ê³µë°±/ëŒ€ì†Œë¬¸ì ë“±)\n",
    "def norm_type(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        return \"ê¸°íƒ€\"\n",
    "    y = x.strip()\n",
    "    # í•„ìš”ì‹œ ì¹˜í™˜ ë£°ì„ ì—¬ê¸° ì¶”ê°€\n",
    "    # ì˜ˆ) 'ì£¼ë¯¼ì‹ ê³ ' â†’ 'ì£¼ë¯¼ì‹ ê³ ì œ'\n",
    "    if y in (\"ì£¼ë¯¼ì‹ ê³ \", \"ì£¼ë¯¼ ì‹ ê³ \"):\n",
    "        y = \"ì£¼ë¯¼ì‹ ê³ \"\n",
    "    return y\n",
    "\n",
    "df['type'] = df['ë‹¨ì†ë°©ë²•'].astype(str).map(norm_type)\n",
    "\n",
    "# ===== 4) ì¢Œí‘œ ì§‘ê³„(í´ëŸ¬ìŠ¤í„°ë§ì€ ì•ˆ í•˜ê³  'ì •í™• ì¢Œí‘œ' ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„) =====\n",
    "#   render.jsëŠ” (lat, lon, hour, type) ë‹¨ìœ„ë¡œ count ì‚¬ìš©\n",
    "group_cols = ['lat', 'lon', 'hour', 'type']\n",
    "agg = (\n",
    "    df.groupby(group_cols, dropna=False)\n",
    "      .size()\n",
    "      .reset_index(name='count')\n",
    "      .sort_values('count', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ===== 5) JSON ì €ì¥ =====\n",
    "# orient=\"records\" â†’ [{lat:.., lon:.., hour:.., type:.., count:..}, ...]\n",
    "agg.to_json(OUTPUT_JSON, orient=\"records\", force_ascii=False)\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {OUTPUT_JSON} (rows={len(agg)})\")\n",
    "\n",
    "# ===== 6) ì°¸ê³ : í•„í„° ì˜µì…˜ì´ í•„ìš”í•˜ë©´ í•œ ë²ˆì— í•¨ê»˜ ì¶œë ¥(ì„ íƒ) =====\n",
    "summary = (\n",
    "    df.groupby('type')\n",
    "      .size()\n",
    "      .reset_index(name='n')\n",
    "      .sort_values('n', ascending=False)\n",
    ")\n",
    "print(\"\\në‹¨ì†ë°©ë²• ë¶„í¬(ìƒìœ„ 10):\")\n",
    "print(summary.head(10).to_string(index=False))\n",
    "\n",
    "hours_cnt = df['hour'].value_counts().sort_index()\n",
    "print(\"\\nì‹œê°„ëŒ€ ë¶„í¬(0~23):\")\n",
    "print(hours_cnt.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e64c0b-623a-4e3d-8b3c-c14d46dfcd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
